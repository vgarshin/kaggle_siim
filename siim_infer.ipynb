{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import json\n",
    "import cv2\n",
    "import time\n",
    "import shutil\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pydicom\n",
    "import glob\n",
    "from pydicom.pixel_data_handlers.util import apply_voi_lut\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import matplotlib.pyplot as plt\n",
    "import albumentations as A\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras import Model, Sequential\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.losses import BinaryCrossentropy, CategoricalCrossentropy\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.callbacks import *\n",
    "from tensorflow.keras.metrics import AUC, CategoricalAccuracy\n",
    "from tqdm import tqdm\n",
    "import efficientnet.tfkeras as efn\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "print('tensorflow version:', tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KAGGLE = False\n",
    "MDLS_FOLDS = {'v10': [0, 1]}\n",
    "MDLS_FOLDS_TWOCLS = {'vbin1': [0, 1]}\n",
    "if KAGGLE:\n",
    "    DATA_PATH = '../input/siim-covid19-detection'\n",
    "    MDLS_PATHS = {ver: f'../input/siim-tfmodels-{ver}' \n",
    "                  for ver, _ in MDLS_FOLDS.items()}\n",
    "    MDLS_PATHS_TWOCLS = {ver: f'../input/siim-tfmodels-{ver}' \n",
    "                         for ver, _ in MDLS_FOLDS_TWOCLS.items()}\n",
    "else:\n",
    "    DATA_PATH = './data'\n",
    "    MDLS_PATHS = {ver: f'./models_{ver}' \n",
    "                  for ver, _ in MDLS_FOLDS.items()}\n",
    "    MDLS_PATHS_TWOCLS = {ver: f'./models_{ver}' \n",
    "                         for ver, _ in MDLS_FOLDS_TWOCLS.items()}\n",
    "CACHE_PATHS = {ver: './cache' for ver, _ in MDLS_FOLDS.items()}\n",
    "CACHE_PATHS_TWOCLS = {ver: './cache' for ver, _ in MDLS_FOLDS_TWOCLS.items()}\n",
    "TTAS = [0, 1]\n",
    "\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All classes model infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_dict = {}\n",
    "for ver, _ in MDLS_FOLDS.items():\n",
    "    with open(f'{MDLS_PATHS[ver]}/params.json') as file:\n",
    "        params_dict[ver] = json.load(file)\n",
    "for ver, params in params_dict.items():\n",
    "    print('version:', ver, '| loaded params:', params, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_xray(path, voi_lut=True, fix_monochrome=True):\n",
    "    dicom = pydicom.read_file(path)\n",
    "    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to \n",
    "    # \"human-friendly\" view\n",
    "    if voi_lut:\n",
    "        data = apply_voi_lut(dicom.pixel_array, dicom)\n",
    "    else:\n",
    "        data = dicom.pixel_array        \n",
    "    # depending on this value, X-ray may look inverted - fix that:\n",
    "    if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n",
    "        data = np.amax(data) - data\n",
    "    data = data - np.min(data)\n",
    "    data = data / np.max(data)\n",
    "    data = (data * 255).astype(np.uint8) \n",
    "    return data\n",
    "\n",
    "def resize(array, size, keep_ratio=False, resample=Image.LANCZOS):\n",
    "    img = Image.fromarray(array)\n",
    "    if keep_ratio:\n",
    "        img.thumbnail((size, size), resample)\n",
    "    else:\n",
    "        img = img.resize((size, size), resample)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepaths = glob.glob(f'{DATA_PATH}/test/**/*dcm', recursive=True)\n",
    "test_df = pd.DataFrame({'path': filepaths,})\n",
    "test_df['image_id'] = test_df.path.map(\n",
    "    lambda x: x.split('/')[-1].replace('.dcm', '') \n",
    "    + '_image'\n",
    ")\n",
    "test_df['study_id'] = test_df.path.map(\n",
    "    lambda x: x.split('/')[-3].replace('.dcm', '') \n",
    "    + '_study'\n",
    ")\n",
    "display(test_df.head())\n",
    "print('test df loaded', test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for ver, params in params_dict.items():\n",
    "    counter = 0\n",
    "    images_paths = []\n",
    "    dim_x = []\n",
    "    dim_y = []\n",
    "    os.makedirs(CACHE_PATHS[ver], exist_ok=True)\n",
    "    for file in tqdm(test_df.path, desc=f'test {ver}'):\n",
    "        if file == '':\n",
    "            counter += 1\n",
    "        else:\n",
    "            xray = read_xray(file)\n",
    "            im = resize(xray, size=params['img_size']) # keep_ratio=True to have original aspect ratio\n",
    "            im.save(CACHE_PATHS[ver] + '/' + file.split('/')[-1].replace('dcm', 'png'))\n",
    "            images_paths.append(file.split('/')[-1].replace('dcm', 'png'))\n",
    "            dim_x.append(xray.shape[1])\n",
    "            dim_y.append(xray.shape[0])\n",
    "    print('files omitted:', counter)\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print(f'time elapsed: {elapsed_time // 60:.0f} min {elapsed_time % 60:.0f} sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['img'] = images_paths\n",
    "test_df['dim_x'] = dim_x\n",
    "test_df['dim_y'] = dim_y\n",
    "display(test_df.head())\n",
    "print('test df done', test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EFNS = [efn.EfficientNetB0, efn.EfficientNetB1, \n",
    "        efn.EfficientNetB2, efn.EfficientNetB3, \n",
    "        efn.EfficientNetB4, efn.EfficientNetB5, \n",
    "        efn.EfficientNetB6, efn.EfficientNetB7]\n",
    "\n",
    "def get_model(params, classes=4, lr=.001, lbl_smth=.0001):\n",
    "    input_shape=(params['img_size'], params['img_size'], 3)\n",
    "    enet = EFNS[params['backbone']](\n",
    "        input_shape=input_shape,\n",
    "        weights='imagenet',\n",
    "        include_top=False\n",
    "    )\n",
    "    inp = Input(shape=input_shape)\n",
    "    x = enet(inp)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(64, activation = 'relu')(x)\n",
    "    if classes == 1:\n",
    "        x = Dense(classes, activation='sigmoid')(x)\n",
    "        loss = BinaryCrossentropy(label_smoothing=params['lbl_smth'])\n",
    "        auc = tf.keras.metrics.AUC(name='auc')\n",
    "        accuracy = 'accuracy'\n",
    "        f1  = tfa.metrics.F1Score(\n",
    "            num_classes=classes, \n",
    "            average='macro', \n",
    "            threshold=None\n",
    "        )\n",
    "    else:\n",
    "        x = Dense(classes, activation='softmax')(x)\n",
    "        loss = CategoricalCrossentropy(label_smoothing=params['lbl_smth'])\n",
    "        auc = AUC(name='auc', curve='ROC', multi_label=True)\n",
    "        accuracy = CategoricalAccuracy()\n",
    "        f1  = tfa.metrics.F1Score(\n",
    "            num_classes=classes, \n",
    "            average='macro', \n",
    "            threshold=None\n",
    "        )\n",
    "    model = Model(inputs=inp, outputs=x)\n",
    "    model.compile(\n",
    "        optimizer=tfa.optimizers.Lookahead(\n",
    "            tf.keras.optimizers.Adam(learning_rate=params['lr']),\n",
    "            sync_period=max(6, int(params['patience'] / 4))\n",
    "        ),\n",
    "        loss=loss, \n",
    "        metrics=[auc, accuracy, f1]\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenSIIM(Sequence):\n",
    "    \n",
    "    def __init__(self, df, classes, imgs_path, imgs_idxs, img_size,\n",
    "                 batch_size=8, mode='fit', shuffle=False, aug=None, \n",
    "                 resize=None, tta=0, two_cls=False):\n",
    "        self.df = df\n",
    "        self.classes = classes\n",
    "        self.imgs_path = imgs_path\n",
    "        self.imgs_idxs = imgs_idxs\n",
    "        self.img_size = img_size\n",
    "        self.batch_size = batch_size\n",
    "        self.mode = mode\n",
    "        self.shuffle = shuffle\n",
    "        self.aug = aug\n",
    "        self.resize = resize\n",
    "        self.tta = tta\n",
    "        self.two_cls = two_cls\n",
    "        self.on_epoch_end()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.imgs_idxs) / self.batch_size))\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(len(self.imgs_idxs))\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "        batch_size = min(self.batch_size, len(self.imgs_idxs) - index*self.batch_size)\n",
    "        X = np.zeros((batch_size, self.img_size, self.img_size, 3), dtype=np.float32)\n",
    "        imgs_batch = self.imgs_idxs[index * self.batch_size : (index+1) * self.batch_size]\n",
    "        if self.mode == 'fit':\n",
    "            if self.two_cls:\n",
    "                y = np.zeros(batch_size, dtype=np.float32)\n",
    "            else:\n",
    "                y = np.zeros((batch_size, len(self.classes)), dtype=np.float32)\n",
    "            for i, img_idx in enumerate(imgs_batch):\n",
    "                X[i, ], y[i] = self.get_img(img_idx)\n",
    "            return X, y\n",
    "        elif self.mode == 'predict':\n",
    "            for i, img_idx in enumerate(imgs_batch):\n",
    "                X[i, ] = self.get_img(img_idx)\n",
    "            return X\n",
    "        else:\n",
    "            raise AttributeError('fit mode parameter error')\n",
    "            \n",
    "    def get_img(self, img_idx):\n",
    "        img_path = f'{self.imgs_path}/{img_idx}'\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            print('error load image:', img_path)\n",
    "        if self.resize:\n",
    "            img = cv2.resize(img, (int(img.shape[1] / self.resize), int(img.shape[0] / self.resize)))\n",
    "        img = img.astype(np.float32) / 255\n",
    "        if self.mode == 'fit':\n",
    "            if self.two_cls:\n",
    "                label = self.df.loc[self.df['img'] == img_idx, 'None Opacity'].values[0]\n",
    "            else:\n",
    "                label = self.df.loc[self.df['img'] == img_idx, self.classes].values[0]\n",
    "            if label is None:\n",
    "                print('error load label:', img_path)\n",
    "            label = label.astype(np.float32)\n",
    "            if self.aug:\n",
    "                img = self.aug(image=img)['image']\n",
    "            return img, label\n",
    "        else:\n",
    "            if self.aug:\n",
    "                img = self.aug(image=img)['image']\n",
    "            img = self.flip(img, axis=self.tta)\n",
    "            return img\n",
    "        \n",
    "    def flip(self, img, axis=0):\n",
    "        if axis == 1:\n",
    "            return img[::-1, :, ]\n",
    "        elif axis == 2:\n",
    "            return img[:, ::-1, ]\n",
    "        elif axis == 3:\n",
    "            return img[::-1, ::-1, ]\n",
    "        else:\n",
    "            return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SUBM = 64\n",
    "imgs_idxs = test_df.img.values\n",
    "preds = []\n",
    "for ver, folds in MDLS_FOLDS.items():\n",
    "    models = []\n",
    "    for n_fold in folds:\n",
    "        checkpoint_path = f'{MDLS_PATHS[ver]}/model_{n_fold}.hdf5'\n",
    "        model = get_model(\n",
    "            params_dict[ver]\n",
    "        )\n",
    "        model.load_weights(checkpoint_path)\n",
    "        models.append(model)\n",
    "        print('ver', ver, '-> model loaded', checkpoint_path)\n",
    "    for tta in TTAS:\n",
    "        print(f'ver {ver} classes {params_dict[ver][\"classes\"]}')\n",
    "        test_datagen = DataGenSIIM(\n",
    "            df=test_df,\n",
    "            classes=params_dict[ver]['classes'],\n",
    "            imgs_path=CACHE_PATHS[ver], \n",
    "            imgs_idxs=imgs_idxs, \n",
    "            img_size=params_dict[ver]['img_size'], \n",
    "            batch_size=BATCH_SUBM, \n",
    "            mode='predict', \n",
    "            shuffle=False,           \n",
    "            aug=None, \n",
    "            resize=None,\n",
    "            tta=tta\n",
    "        )\n",
    "        for i, model in enumerate(models):\n",
    "            preds.append(model.predict(test_datagen))\n",
    "            print(f'ver {ver} | tta {tta} | model {i} -> prediction done')\n",
    "    del models; gc.collect()\n",
    "preds = np.array(np.mean(preds, axis=0))\n",
    "print('all done | preds shape:', preds.shape)\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print(f'time elapsed: {elapsed_time // 60:.0f} min {elapsed_time % 60:.0f} sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name2fname = {\n",
    "    'Negative for Pneumonia': 'negative', \n",
    "    'Typical Appearance': 'typical', \n",
    "    'Indeterminate Appearance': 'indeterminate', \n",
    "    'Atypical Appearance': 'atypical'\n",
    "}\n",
    "name2label = {v: i for i, (k, v) in enumerate(name2fname.items())}\n",
    "print(name2label)\n",
    "label2name  = {v:k for k, v in name2label.items()}\n",
    "print(label2name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_classes = [str(x) for x in list(name2label.values())]\n",
    "for i, col in enumerate(cols_classes):\n",
    "    test_df[col] = preds[:, i]\n",
    "display(test_df.head())\n",
    "print('test df study part done', test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 class model infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_dict = {}\n",
    "for ver, _ in MDLS_FOLDS_TWOCLS.items():\n",
    "    with open(f'{MDLS_PATHS_TWOCLS[ver]}/params.json') as file:\n",
    "        params_dict[ver] = json.load(file)\n",
    "for ver, params in params_dict.items():\n",
    "    print('version:', ver, '| loaded params:', params, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SUBM = 64\n",
    "imgs_idxs = test_df.img.values\n",
    "preds = []\n",
    "for ver, folds in MDLS_FOLDS_TWOCLS.items():\n",
    "    models = []\n",
    "    for n_fold in folds:\n",
    "        checkpoint_path = f'{MDLS_PATHS_TWOCLS[ver]}/model_{n_fold}.hdf5'\n",
    "        model = get_model(\n",
    "            params_dict[ver],\n",
    "            classes=1\n",
    "        )\n",
    "        model.load_weights(checkpoint_path)\n",
    "        models.append(model)\n",
    "        print('ver', ver, '-> model loaded', checkpoint_path)\n",
    "    for tta in TTAS:\n",
    "        print(f'ver {ver} classes {params_dict[ver][\"classes\"]}')\n",
    "        test_datagen = DataGenSIIM(\n",
    "            df=test_df,\n",
    "            classes=params_dict[ver]['classes'],\n",
    "            imgs_path=CACHE_PATHS_TWOCLS[ver], \n",
    "            imgs_idxs=imgs_idxs, \n",
    "            img_size=params_dict[ver]['img_size'], \n",
    "            batch_size=BATCH_SUBM, \n",
    "            mode='predict', \n",
    "            shuffle=False,           \n",
    "            aug=None, \n",
    "            resize=None,\n",
    "            tta=tta,\n",
    "            two_cls=True\n",
    "        )\n",
    "        for i, model in enumerate(models):\n",
    "            preds.append(model.predict(test_datagen))\n",
    "            print(f'ver {ver} | tta {tta} | model {i} -> prediction done')\n",
    "    del models; gc.collect()\n",
    "preds = np.array(np.mean(preds, axis=0))\n",
    "print('all done | preds shape:', preds.shape)\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print(f'time elapsed: {elapsed_time // 60:.0f} min {elapsed_time % 60:.0f} sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['None Opacity'] = preds\n",
    "display(test_df.head())\n",
    "print('test df study part done', test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MMDet model infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mmcv\n",
    "import mmdet\n",
    "from numba import cuda\n",
    "from ensemble_boxes import *\n",
    "from mmdet.apis import init_detector, inference_detector\n",
    "print(mmdet.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda.select_device(0)\n",
    "cuda.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BXS = True\n",
    "VER_BXS = 'v0'\n",
    "if KAGGLE:\n",
    "    MDLS_BXS_PATH = f'../input/siim-mmdetection-train-demo' \n",
    "else:\n",
    "    MDLS_BXS_PATH = f'/u01/mrorange/siim/models_mmdet_{VER_BXS}'\n",
    "TH = .35\n",
    "IOU_TH = .6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{MDLS_BXS_PATH}/params.json') as file:\n",
    "    params_bxs = json.load(file)\n",
    "print(params_bxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = f'{MDLS_BXS_PATH}/epoch_6.pth'\n",
    "cfg = f'{MDLS_BXS_PATH}/init_config.py'\n",
    "model_bxs = init_detector(cfg, checkpoint, device='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_imgs(imgs, cols=2, size=10, is_rgb=True, title='', cmap='gray', img_size=None):\n",
    "    rows = len(imgs) // cols + 1\n",
    "    fig = plt.figure(figsize=(cols * size, rows * size))\n",
    "    for i, img in enumerate(imgs):\n",
    "        if img_size is not None:\n",
    "            img = cv2.resize(img, img_size)\n",
    "        fig.add_subplot(rows, cols, i + 1)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(img, cmap=cmap)\n",
    "    plt.suptitle(title)\n",
    "    plt.axis('off')\n",
    "    \n",
    "def draw_bbox(img, box, label, color, thickness=3):   \n",
    "    alpha = .1\n",
    "    alpha_box = .4\n",
    "    overlay_bbox = img.copy()\n",
    "    overlay_text = img.copy()\n",
    "    output = img.copy()\n",
    "    text_width, text_height = cv2.getTextSize(label.upper(), cv2.FONT_HERSHEY_SIMPLEX, .6, 1)[0]\n",
    "    cv2.rectangle(overlay_bbox, \n",
    "                  (box[0], box[1]), \n",
    "                  (box[2], box[3]), \n",
    "                  color, -1)\n",
    "    cv2.addWeighted(overlay_bbox, alpha, output, 1 - alpha, 0, output)\n",
    "    cv2.rectangle(overlay_text, \n",
    "                  (box[0], box[1] - 7 - text_height), \n",
    "                  (box[0] + text_width + 2, box[1]),\n",
    "                  (0, 0, 0), -1)\n",
    "    cv2.addWeighted(overlay_text, alpha_box, output, 1 - alpha_box, 0, output)\n",
    "    cv2.rectangle(output, \n",
    "                  (box[0], box[1]), \n",
    "                  (box[2], box[3]),\n",
    "                  color, thickness)\n",
    "    cv2.putText(output, \n",
    "                label.upper(), \n",
    "                (box[0], box[1]-5),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                .6, (255, 255, 255), 1, \n",
    "                cv2.LINE_AA)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = []\n",
    "preds_bxs = []\n",
    "for ver, params in params_dict.items():\n",
    "    for i, img_name in enumerate(tqdm(imgs_idxs, desc=f'test {ver}')):\n",
    "        ratio_x = params['img_size'] / test_df.loc[test_df['img'] == img_name, 'dim_x'].values[0]\n",
    "        ratio_y = params['img_size'] / test_df.loc[test_df['img'] == img_name, 'dim_y'].values[0]\n",
    "        img = cv2.imread(f'{CACHE_PATHS_TWOCLS[ver]}/{img_name}')\n",
    "        result = inference_detector(model_bxs, img)\n",
    "        boxes_list = [list(x[:, :4] / params['img_size']) for x in result if x.shape[0] != 0]\n",
    "        boxes_list =  [item for sublist in boxes_list for item in sublist]\n",
    "        scores_list = [x[:, 4].tolist() for x in result if x.shape[0] != 0]\n",
    "        scores_list =  [item for sublist in scores_list for item in sublist]\n",
    "        labels_list = [[i] * x.shape[0] for i, x in enumerate(result) if x.shape[0] != 0]\n",
    "        labels_list =  [item for sublist in labels_list for item in sublist]\n",
    "        boxes, scores, box_labels = nms(\n",
    "            boxes=[boxes_list], \n",
    "            scores=[scores_list], \n",
    "            labels=[labels_list], \n",
    "            weights=None,\n",
    "            iou_thr=IOU_TH\n",
    "        )\n",
    "        boxes *= params['img_size']\n",
    "        if i <= 3:\n",
    "            for label_id, box, score in zip(box_labels, boxes, scores):\n",
    "                if score >= TH:\n",
    "                    color = [255, 255, 255]\n",
    "                    img = draw_bbox(\n",
    "                        img, \n",
    "                        list(np.int_(box)), \n",
    "                        'predict', \n",
    "                        color\n",
    "                    )\n",
    "            imgs.append(img)\n",
    "        string = ''\n",
    "        for label_id, box, score in zip(box_labels, boxes, scores):\n",
    "            if score >= TH:\n",
    "                str_boxes = ' '.join([\n",
    "                    str(int(box[0] / ratio_x)),\n",
    "                    str(int(box[1] / ratio_y)),\n",
    "                    str(int(box[2] / ratio_x)),\n",
    "                    str(int(box[3] / ratio_y))\n",
    "                ])\n",
    "                string += f'opacity {score:0.2f} {str_boxes} '\n",
    "        string = string.strip()\n",
    "        preds_bxs.append(string if string else 'none 1 0 0 1 1')\n",
    "    plot_imgs(imgs, size=8, cols=4, cmap=None)\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print(f'time elapsed: {elapsed_time // 60:.0f} min {elapsed_time % 60:.0f} sec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post-processing for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if BXS:\n",
    "    image_df = pd.DataFrame({\n",
    "        'image_id': test_df.image_id.tolist(),\n",
    "        'PredictionString_img': preds_bxs\n",
    "    })\n",
    "else:\n",
    "    image_df = pd.DataFrame({\n",
    "        'image_id': test_df.image_id.tolist(),\n",
    "        'PredictionString_img': [\"none 1 0 0 1 1\"] * len(test_df.image_id.tolist())\n",
    "    })\n",
    "display(image_df.head())\n",
    "print('image df done', image_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predstring(row, thr=0):\n",
    "    string = ''\n",
    "    for idx in range(4):\n",
    "        conf =  row[str(idx)]\n",
    "        if conf > thr:\n",
    "            string += f'{label2name[idx]} {conf:0.2f} 0 0 1 1 '\n",
    "    string = string.strip()\n",
    "    return string\n",
    "\n",
    "def get_prednoneop(row):\n",
    "    string = row['PredictionString_img']\n",
    "    if string != 'none 1 0 0 1 1':\n",
    "        string += f' none {row[\"None Opacity\"]:0.2f} 0 0 1 1'\n",
    "    string = string.strip()\n",
    "    return string\n",
    "\n",
    "def get_negative(row):\n",
    "    string = row['PredictionString_img']\n",
    "    if np.argmax(row[cols_classes]) == 0:\n",
    "        string = 'none 0 0 1 1'\n",
    "    string = string.strip()\n",
    "    return string\n",
    "\n",
    "cols = ['image_id', 'study_id']\n",
    "print('test shape:', test_df.shape)\n",
    "subm_df = pd.merge(test_df[cols], image_df, \n",
    "                   left_on='image_id', right_on='image_id', \n",
    "                   how='left')\n",
    "subm_df = pd.merge(subm_df, \n",
    "                   test_df.groupby(['study_id'])[cols_classes].mean().reset_index(), \n",
    "                   left_on='study_id', right_on='study_id', \n",
    "                   how='left')\n",
    "subm_df = pd.merge(subm_df, \n",
    "                   test_df.groupby(['study_id'])['None Opacity'].mean().reset_index(), \n",
    "                   left_on='study_id', right_on='study_id', \n",
    "                   how='left')\n",
    "subm_df['PredictionString_sty'] = subm_df.apply(get_predstring, axis=1)\n",
    "subm_df['PredictionString_img'] = subm_df.apply(get_prednoneop, axis=1)\n",
    "subm_df['PredictionString_img'] = subm_df.apply(get_negative, axis=1)\n",
    "display(subm_df.head())\n",
    "print('unique study ids:', len(subm_df.study_id.unique()))\n",
    "print('unique image ids:', len(subm_df.image_id.unique()))\n",
    "print('subm shape:', subm_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subm_df = pd.concat([\n",
    "    subm_df[['image_id', 'PredictionString_img']].rename(\n",
    "        columns={'image_id': 'id', 'PredictionString_img': 'PredictionString'}\n",
    "    ).drop_duplicates(), \n",
    "    subm_df[['study_id', 'PredictionString_sty']].rename(\n",
    "        columns={'study_id': 'id', 'PredictionString_sty': 'PredictionString'}\n",
    "    ).drop_duplicates()\n",
    "])\n",
    "subm_df.to_csv('submission.csv', index=False)\n",
    "display(subm_df.head())\n",
    "print('submission done:', subm_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ver, cache_path in CACHE_PATHS.items():\n",
    "    shutil.rmtree(cache_path)\n",
    "    print(f'ver {ver} | path {cache_path} -> cache deleted')\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print(f'time elapsed: {elapsed_time // 60:.0f} min {elapsed_time % 60:.0f} sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Orange Python 3",
   "language": "python",
   "name": "orange"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
