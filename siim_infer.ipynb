{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import time\n",
    "import shutil\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pydicom\n",
    "import glob\n",
    "from pydicom.pixel_data_handlers.util import apply_voi_lut\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import matplotlib.pyplot as plt\n",
    "import albumentations as A\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras import Model, Sequential\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.losses import binary_crossentropy, CategoricalCrossentropy\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.callbacks import *\n",
    "from tensorflow.keras.metrics import AUC, CategoricalAccuracy\n",
    "from tqdm import tqdm\n",
    "import efficientnet.tfkeras as efn\n",
    "print('tensorflow version:', tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KAGGLE = False\n",
    "MDLS_FOLDS = {'v0': [0, 1, 2, 3]}\n",
    "if KAGGLE:\n",
    "    DATA_PATH = '../input/siim-covid19-detection'\n",
    "    MDLS_PATHS = {ver: f'../input/siim-tfmodels-{ver}' \n",
    "                  for ver, _ in MDLS_FOLDS.items()}\n",
    "else:\n",
    "    DATA_PATH = './data'\n",
    "    MDLS_PATHS = {ver: f'./models_{ver}' \n",
    "                  for ver, _ in MDLS_FOLDS.items()}\n",
    "CACHE_PATHS = {ver: f'./cache_{ver}' for ver, _ in MDLS_FOLDS.items()}\n",
    "TTAS = [0, 1, 2]\n",
    "\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_dict = {}\n",
    "for ver, _ in MDLS_FOLDS.items():\n",
    "    with open(f'{MDLS_PATHS[ver]}/params.json') as file:\n",
    "        params_dict[ver] = json.load(file)\n",
    "for ver, params in params_dict.items():\n",
    "    print('version:', ver, '| loaded params:', params_dict, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_xray(path, voi_lut=True, fix_monochrome=True):\n",
    "    dicom = pydicom.read_file(path)\n",
    "    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to \n",
    "    # \"human-friendly\" view\n",
    "    if voi_lut:\n",
    "        data = apply_voi_lut(dicom.pixel_array, dicom)\n",
    "    else:\n",
    "        data = dicom.pixel_array        \n",
    "    # depending on this value, X-ray may look inverted - fix that:\n",
    "    if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n",
    "        data = np.amax(data) - data\n",
    "    data = data - np.min(data)\n",
    "    data = data / np.max(data)\n",
    "    data = (data * 255).astype(np.uint8) \n",
    "    return data\n",
    "\n",
    "def resize(array, size, keep_ratio=False, resample=Image.LANCZOS):\n",
    "    img = Image.fromarray(array)\n",
    "    if keep_ratio:\n",
    "        img.thumbnail((size, size), resample)\n",
    "    else:\n",
    "        img = img.resize((size, size), resample)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepaths = glob.glob(f'{DATA_PATH}/test/**/*dcm', recursive=True)\n",
    "test_df = pd.DataFrame({'path': filepaths,})\n",
    "test_df['image_id'] = test_df.path.map(\n",
    "    lambda x: x.split('/')[-1].replace('.dcm', '') \n",
    "    + '_image'\n",
    ")\n",
    "test_df['study_id'] = test_df.path.map(\n",
    "    lambda x: x.split('/')[-3].replace('.dcm', '') \n",
    "    + '_study'\n",
    ")\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for ver, params in params_dict.items():\n",
    "    counter = 0\n",
    "    images_paths = []\n",
    "    dim_x = []\n",
    "    dim_y = []\n",
    "    os.makedirs(CACHE_PATHS[ver], exist_ok=True)\n",
    "    for file in tqdm(test_df.path, desc=f'test {ver}'):\n",
    "        if file == '':\n",
    "            counter += 1\n",
    "        else:\n",
    "            xray = read_xray(file)\n",
    "            im = resize(xray, size=params['img_size']) # keep_ratio=True to have original aspect ratio\n",
    "            im.save(CACHE_PATHS[ver] + '/' + file.split('/')[-1].replace('dcm', 'png'))\n",
    "            images_paths.append(file.split('/')[-1].replace('dcm', 'png'))\n",
    "            dim_x.append(xray.shape[1])\n",
    "            dim_y.append(xray.shape[0])\n",
    "    print('files omitted:', counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['img'] = images_paths\n",
    "test_df['dim_x'] = dim_x\n",
    "test_df['dim_y'] = dim_y\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EFNS = [efn.EfficientNetB0, efn.EfficientNetB1, \n",
    "        efn.EfficientNetB2, efn.EfficientNetB3, \n",
    "        efn.EfficientNetB4, efn.EfficientNetB5, \n",
    "        efn.EfficientNetB6, efn.EfficientNetB7]\n",
    "\n",
    "def get_model(params, classes=4, lr=.001, lbl_smth=.0001):\n",
    "    input_shape=(params['img_size'], params['img_size'], 3)\n",
    "    enet = EFNS[params['backbone']](\n",
    "        input_shape=input_shape,\n",
    "        weights=None,\n",
    "        include_top=False\n",
    "    )\n",
    "    inp = Input(shape=input_shape)\n",
    "    x = enet(inp)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(64, activation = 'relu')(x)\n",
    "    x = Dense(classes, activation='softmax')(x)\n",
    "    model = Model(inputs=inp, outputs=x)\n",
    "    loss = CategoricalCrossentropy(label_smoothing=params['lbl_smth'])\n",
    "    auc = AUC(name='auc', curve='ROC', multi_label=True)\n",
    "    accuracy = CategoricalAccuracy()\n",
    "    f1  = tfa.metrics.F1Score(\n",
    "        num_classes=classes, \n",
    "        average='macro', \n",
    "        threshold=None\n",
    "    )\n",
    "    model.compile(\n",
    "        optimizer=tfa.optimizers.Lookahead(\n",
    "            tf.keras.optimizers.Adam(learning_rate=params['lr']),\n",
    "            sync_period=max(6, int(params['patience'] / 4))\n",
    "        ),\n",
    "        loss=loss, \n",
    "        metrics=[auc, accuracy, f1]\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenSIIM(Sequence):\n",
    "    \n",
    "    def __init__(self, df, classes, imgs_path, imgs_idxs, img_size,\n",
    "                 batch_size=8, mode='fit', shuffle=False, aug=None, \n",
    "                 resize=None, tta=0):\n",
    "        self.df = df\n",
    "        self.classes = classes\n",
    "        self.imgs_path = imgs_path\n",
    "        self.imgs_idxs = imgs_idxs\n",
    "        self.img_size = img_size\n",
    "        self.batch_size = batch_size\n",
    "        self.mode = mode\n",
    "        self.shuffle = shuffle\n",
    "        self.aug = aug\n",
    "        self.resize = resize\n",
    "        self.tta = tta\n",
    "        self.on_epoch_end()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.imgs_idxs) / self.batch_size))\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(len(self.imgs_idxs))\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "        batch_size = min(self.batch_size, len(self.imgs_idxs) - index*self.batch_size)\n",
    "        X = np.zeros((batch_size, self.img_size, self.img_size, 3), dtype=np.float32)\n",
    "        imgs_batch = self.imgs_idxs[index * self.batch_size : (index+1) * self.batch_size]\n",
    "        if self.mode == 'fit':\n",
    "            y = np.zeros((batch_size, len(self.classes)), dtype=np.float32)\n",
    "            for i, img_idx in enumerate(imgs_batch):\n",
    "                X[i, ], y[i] = self.get_img(img_idx)\n",
    "            return X, y\n",
    "        elif self.mode == 'predict':\n",
    "            for i, img_idx in enumerate(imgs_batch):\n",
    "                X[i, ] = self.get_img(img_idx)\n",
    "            return X\n",
    "        else:\n",
    "            raise AttributeError('fit mode parameter error')\n",
    "            \n",
    "    def get_img(self, img_idx):\n",
    "        img_path = f'{self.imgs_path}/{img_idx}'\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            print('error load image:', img_path)\n",
    "        if self.resize:\n",
    "            img = cv2.resize(img, (int(img.shape[1] / self.resize), int(img.shape[0] / self.resize)))\n",
    "        img = img.astype(np.float32) / 255\n",
    "        if self.mode == 'fit':\n",
    "            label = self.df.loc[self.df['img'] == img_idx, self.classes].values[0]\n",
    "            if label is None:\n",
    "                print('error load label:', img_path)\n",
    "            label = label.astype(np.float32)\n",
    "            if self.aug:\n",
    "                img = self.aug(image=img)['image']\n",
    "            return img, label\n",
    "        else:\n",
    "            if self.aug:\n",
    "                img = self.aug(image=img)['image']\n",
    "            img = self.flip(img, axis=self.tta)\n",
    "            return img\n",
    "        \n",
    "    def flip(self, img, axis=0):\n",
    "        if axis == 1:\n",
    "            return img[::-1, :, ]\n",
    "        elif axis == 2:\n",
    "            return img[:, ::-1, ]\n",
    "        elif axis == 3:\n",
    "            return img[::-1, ::-1, ]\n",
    "        else:\n",
    "            return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "for ver, folds in MDLS_FOLDS.items():\n",
    "    for n_fold in folds:\n",
    "        checkpoint_path = f'{MDLS_PATHS[ver]}/model_{n_fold}.hdf5'\n",
    "        model = get_model(\n",
    "            params_dict[ver]\n",
    "        )\n",
    "        model.load_weights(checkpoint_path)\n",
    "        models.append(model)\n",
    "        print('ver:', ver, '| model loaded:', checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_idxs = test_df.img.values\n",
    "test_datagen = DataGenSIIM(\n",
    "    df=test_df,\n",
    "    classes=params_dict['v0']['classes'],\n",
    "    imgs_path=CACHE_PATHS['v0'], \n",
    "    imgs_idxs=imgs_idxs, \n",
    "    img_size=320, \n",
    "    batch_size=100, \n",
    "    mode='predict', \n",
    "    shuffle=False,           \n",
    "    aug=None, \n",
    "    resize=None,\n",
    "    tta=0\n",
    ")\n",
    "bsize = min(4, 8)\n",
    "Xt = test_datagen.__getitem__(0)\n",
    "print('test X: ', Xt.shape)\n",
    "fig, axes = plt.subplots(figsize=(16, 4), nrows=1, ncols=bsize)\n",
    "for j in range(bsize):\n",
    "    axes[j].imshow(Xt[j])\n",
    "    axes[j].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SUBM = 64\n",
    "preds = []\n",
    "for ver, folds in MDLS_FOLDS.items():\n",
    "    models = []\n",
    "    for n_fold in folds:\n",
    "        checkpoint_path = f'{MDLS_PATHS[ver]}/model_{n_fold}.hdf5'\n",
    "        model = get_model(\n",
    "            params_dict[ver]\n",
    "        )\n",
    "        model.load_weights(checkpoint_path)\n",
    "        models.append(model)\n",
    "        print('ver', ver, '-> model loaded', checkpoint_path)\n",
    "    for tta in TTAS:\n",
    "        print(f'ver {ver} classes {params_dict[ver][\"classes\"]}')\n",
    "        test_datagen = DataGenSIIM(\n",
    "            df=test_df,\n",
    "            classes=params_dict[ver]['classes'],\n",
    "            imgs_path=CACHE_PATHS[ver], \n",
    "            imgs_idxs=imgs_idxs, \n",
    "            img_size=params_dict[ver]['img_size'], \n",
    "            batch_size=BATCH_SUBM, \n",
    "            mode='predict', \n",
    "            shuffle=False,           \n",
    "            aug=None, \n",
    "            resize=None,\n",
    "            tta=tta\n",
    "        )\n",
    "        for i, model in enumerate(models):\n",
    "            preds.append(model.predict(test_datagen))\n",
    "            print(f'ver {ver} | tta {tta} | model {i} -> prediction done')\n",
    "preds = np.array(np.mean(preds, axis=0))\n",
    "print('all done | preds shape:', preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name2fname = {\n",
    "    'Negative for Pneumonia': 'negative', \n",
    "    'Typical Appearance': 'typical', \n",
    "    'Indeterminate Appearance': 'indeterminate', \n",
    "    'Atypical Appearance': 'atypical'\n",
    "    \n",
    "}\n",
    "name2label = {v: i for i, (k, v) in enumerate(name2fname.items())}\n",
    "print(name2label)\n",
    "label2name  = {v:k for k, v in name2label.items()}\n",
    "print(label2name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_classes = [str(x) for x in list(name2label.values())]\n",
    "for i, col in enumerate(cols_classes):\n",
    "    test_df[col] = preds[:, i]\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_df = test_df.groupby(['study_id'])[cols_classes].mean().reset_index()\n",
    "study_df.rename(columns={'study_id':'id'}, inplace=True)\n",
    "study_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predstring(row, thr=0):\n",
    "    string = ''\n",
    "    for idx in range(4):\n",
    "        conf =  row[str(idx)]\n",
    "        if conf > thr:\n",
    "            string += f'{label2name[idx]} {conf:0.2f} 0 0 1 1 '\n",
    "    string = string.strip()\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_df['PredictionString'] = study_df.apply(get_predstring, axis=1)\n",
    "study_df = study_df.drop(cols_classes, axis=1)\n",
    "study_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_df = pd.DataFrame({\n",
    "    'id':test_df.image_id.tolist(),\n",
    "    'PredictionString':[\"none 1 0 0 1 1\"]*len(test_df.image_id.tolist())\n",
    "})\n",
    "image_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subm_df = pd.concat([study_df, image_df])\n",
    "subm_df.to_csv('submission.csv', index=False)\n",
    "display(subm_df.head())\n",
    "print('submission done:', subm_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ver, cache_path in CACHE_PATHS.items():\n",
    "    shutil.rmtree(cache_path)\n",
    "    print(f'ver {ver} | path {cache_path} -> cache deleted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Orange Python 3",
   "language": "python",
   "name": "orange"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
