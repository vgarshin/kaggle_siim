{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YADSPH = False\n",
    "DEBUG = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ev0CPJwP4-9C",
    "outputId": "b83278db-61ba-47a9-9d0d-06e71170400a"
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import sys \n",
    "import random \n",
    "import time \n",
    "import json\n",
    "from glob import glob \n",
    "import pandas as pd \n",
    "import timm\n",
    "from timm.models.efficientnet import *\n",
    "import numpy as np \n",
    "from tqdm.notebook import tqdm \n",
    "import gc \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "import cv2\n",
    "import pydicom\n",
    "from pydicom.pixel_data_handlers.util import apply_voi_lut\n",
    "import scipy \n",
    "from scipy import stats\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from ast import literal_eval\n",
    "import sklearn \n",
    "from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold \n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, average_precision_score, precision_score \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim \n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import GradScaler, autocast \n",
    "from torch.autograd import Variable\n",
    "from torch.nn.modules.loss import _WeightedLoss\n",
    "import typing as tp\n",
    "try:\n",
    "    from itertools import  ifilterfalse\n",
    "except ImportError: # py3k\n",
    "    from itertools import  filterfalse\n",
    "import warnings \n",
    "if not DEBUG:\n",
    "    warnings.filterwarnings('ignore')\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device('cuda')\n",
    "    print('GPU is available')\n",
    "else:\n",
    "    DEVICE = torch.device('cpu')\n",
    "    print('CPU is used')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fzGHI-xW6QOV"
   },
   "outputs": [],
   "source": [
    "VER = 'vptbin_TEST'\n",
    "PARAMS = {\n",
    "    'version': VER,\n",
    "    'seed': 2021,\n",
    "    'train_bs': 8,\n",
    "    'valid_bs': 16,\n",
    "    'image_size': 512,\n",
    "    'amp': True,\n",
    "    'accum_iter': 2,\n",
    "    'init_lr': 5e-4,\n",
    "    'model_arch': 'tf_efficientnetv2_m', # effb3 with aux loss \n",
    "    'n_workers': 8,\n",
    "    'splits': 5,\n",
    "    'epochs': 200,\n",
    "    't_max': 100,\n",
    "    'patience': 2 if DEBUG else 20,\n",
    "    'device': ('cuda' if torch.cuda.is_available() else 'cpu'),\n",
    "    'n_classes': 1,\n",
    "    'n_channel': 3\n",
    "}\n",
    "DATA_PATH = './data'\n",
    "if YADSPH:\n",
    "    DATASET_PATH = f'./data2/SIIM-COVID19-Resized/img_sz_{PARAMS[\"img_size\"]}'\n",
    "    IMGS_PATH = f'{DATASET_PATH}/train'\n",
    "else:\n",
    "    IMGS_PATH = f'{DATA_PATH}/train_{PARAMS[\"image_size\"]}'\n",
    "    MASKS_PATH = f'{DATA_PATH}/train_{PARAMS[\"image_size\"]}_masks'\n",
    "MDLS_PATH = f'./models_{VER}'\n",
    "if not os.path.exists(MDLS_PATH):\n",
    "    os.mkdir(MDLS_PATH)\n",
    "with open(f'{MDLS_PATH}/params.json', 'w') as file:\n",
    "    json.dump(PARAMS, file)\n",
    "    \n",
    "def seed_all(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True \n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_all(PARAMS['seed'])\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lovasz_grad(gt_sorted):\n",
    "    \"\"\"\n",
    "    Computes gradient of the Lovasz extension w.r.t sorted errors\n",
    "    See Alg. 1 in paper\n",
    "    \"\"\"\n",
    "    p = len(gt_sorted)\n",
    "    gts = gt_sorted.sum()\n",
    "    intersection = gts - gt_sorted.float().cumsum(0)\n",
    "    union = gts + (1 - gt_sorted).float().cumsum(0)\n",
    "    jaccard = 1. - intersection / union\n",
    "    if p > 1: # cover 1-pixel case\n",
    "        jaccard[1:p] = jaccard[1:p] - jaccard[0:-1]\n",
    "    return jaccard\n",
    "\n",
    "def iou_binary(preds, labels, EMPTY=1., ignore=None, per_image=True):\n",
    "    \"\"\"\n",
    "    IoU for foreground class\n",
    "    binary: 1 foreground, 0 background\n",
    "    \"\"\"\n",
    "    if not per_image:\n",
    "        preds, labels = (preds,), (labels,)\n",
    "    ious = []\n",
    "    for pred, label in zip(preds, labels):\n",
    "        intersection = ((label == 1) & (pred == 1)).sum()\n",
    "        union = ((label == 1) | ((pred == 1) & (label != ignore))).sum()\n",
    "        if not union:\n",
    "            iou = EMPTY\n",
    "        else:\n",
    "            iou = float(intersection) / union\n",
    "        ious.append(iou)\n",
    "    iou = mean(ious)    # mean accross images if per_image\n",
    "    return 100 * iou\n",
    "\n",
    "def iou(preds, labels, C, EMPTY=1., ignore=None, per_image=False):\n",
    "    \"\"\"\n",
    "    Array of IoU for each (non ignored) class\n",
    "    \"\"\"\n",
    "    if not per_image:\n",
    "        preds, labels = (preds,), (labels,)\n",
    "    ious = []\n",
    "    for pred, label in zip(preds, labels):\n",
    "        iou = []    \n",
    "        for i in range(C):\n",
    "            if i != ignore: # The ignored label is sometimes among predicted classes (ENet - CityScapes)\n",
    "                intersection = ((label == i) & (pred == i)).sum()\n",
    "                union = ((label == i) | ((pred == i) & (label != ignore))).sum()\n",
    "                if not union:\n",
    "                    iou.append(EMPTY)\n",
    "                else:\n",
    "                    iou.append(float(intersection) / union)\n",
    "        ious.append(iou)\n",
    "    ious = map(mean, zip(*ious)) # mean accross images if per_image\n",
    "    return 100 * np.array(ious)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BINARY LOSSES\n",
    "\n",
    "def lovasz_hinge(logits, labels, per_image=True, ignore=None):\n",
    "    \"\"\"\n",
    "    Binary Lovasz hinge loss\n",
    "      logits: [B, H, W] Variable, logits at each pixel (between -\\infty and +\\infty)\n",
    "      labels: [B, H, W] Tensor, binary ground truth masks (0 or 1)\n",
    "      per_image: compute the loss per image instead of per batch\n",
    "      ignore: void class id\n",
    "    \"\"\"\n",
    "    if per_image:\n",
    "        loss = mean(\n",
    "            lovasz_hinge_flat(\n",
    "                *flatten_binary_scores(log.unsqueeze(0), lab.unsqueeze(0), ignore)\n",
    "            ) \n",
    "            for log, lab in zip(logits, labels)\n",
    "        )\n",
    "    else:\n",
    "        loss = lovasz_hinge_flat(*flatten_binary_scores(logits, labels, ignore))\n",
    "    return loss\n",
    "\n",
    "def lovasz_hinge_flat(logits, labels):\n",
    "    \"\"\"\n",
    "    Binary Lovasz hinge loss\n",
    "      logits: [P] Variable, logits at each prediction (between -\\infty and +\\infty)\n",
    "      labels: [P] Tensor, binary ground truth labels (0 or 1)\n",
    "      ignore: label to ignore\n",
    "    \"\"\"\n",
    "    if len(labels) == 0:\n",
    "        # only void pixels, the gradients should be 0\n",
    "        return logits.sum() * 0.\n",
    "    signs = 2. * labels.float() - 1.\n",
    "    errors = (1. - logits * Variable(signs))\n",
    "    errors_sorted, perm = torch.sort(errors, dim=0, descending=True)\n",
    "    perm = perm.data\n",
    "    gt_sorted = labels[perm]\n",
    "    grad = lovasz_grad(gt_sorted)\n",
    "    #loss = torch.dot(F.relu(errors_sorted), Variable(grad))\n",
    "    loss = torch.dot(F.elu(errors_sorted) + 1, Variable(grad))\n",
    "    return loss\n",
    "\n",
    "def flatten_binary_scores(scores, labels, ignore=None):\n",
    "    \"\"\"\n",
    "    Flattens predictions in the batch (binary case)\n",
    "    Remove labels equal to 'ignore'\n",
    "    \"\"\"\n",
    "    scores = scores.view(-1)\n",
    "    labels = labels.view(-1)\n",
    "    if ignore is None:\n",
    "        return scores, labels\n",
    "    valid = (labels != ignore)\n",
    "    vscores = scores[valid]\n",
    "    vlabels = labels[valid]\n",
    "    return vscores, vlabels\n",
    "\n",
    "class StableBCELoss(torch.nn.modules.Module):\n",
    "    def __init__(self):\n",
    "        super(StableBCELoss, self).__init__()\n",
    "    def forward(self, input, target):\n",
    "        neg_abs = - input.abs()\n",
    "        loss = input.clamp(min=0) - input * target + (1 + neg_abs.exp()).log()\n",
    "        return loss.mean()\n",
    "\n",
    "def binary_xloss(logits, labels, ignore=None):\n",
    "    \"\"\"\n",
    "    Binary Cross entropy loss\n",
    "      logits: [B, H, W] Variable, logits at each pixel (between -\\infty and +\\infty)\n",
    "      labels: [B, H, W] Tensor, binary ground truth masks (0 or 1)\n",
    "      ignore: void class id\n",
    "    \"\"\"\n",
    "    logits, labels = flatten_binary_scores(logits, labels, ignore)\n",
    "    loss = StableBCELoss()(logits, Variable(labels.float()))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MULTICLASS LOSSES\n",
    "\n",
    "def lovasz_softmax(probas, labels, only_present=False, per_image=False, ignore=None):\n",
    "    \"\"\"\n",
    "    Multi-class Lovasz-Softmax loss\n",
    "      probas: [B, C, H, W] Variable, class probabilities at each prediction (between 0 and 1)\n",
    "      labels: [B, H, W] Tensor, ground truth labels (between 0 and C - 1)\n",
    "      only_present: average only on classes present in ground truth\n",
    "      per_image: compute the loss per image instead of per batch\n",
    "      ignore: void class labels\n",
    "    \"\"\"\n",
    "    if per_image:\n",
    "        loss = mean(\n",
    "            lovasz_softmax_flat(\n",
    "                *flatten_probas(prob.unsqueeze(0), lab.unsqueeze(0), ignore), \n",
    "                only_present=only_present\n",
    "            )\n",
    "            for prob, lab in zip(probas, labels)\n",
    "        )\n",
    "    else:\n",
    "        loss = lovasz_softmax_flat(\n",
    "            *flatten_probas(probas, labels, ignore), \n",
    "            only_present=only_present\n",
    "        )\n",
    "    return loss\n",
    "\n",
    "def lovasz_softmax_flat(probas, labels, only_present=False):\n",
    "    \"\"\"\n",
    "    Multi-class Lovasz-Softmax loss\n",
    "      probas: [P, C] Variable, class probabilities at each prediction (between 0 and 1)\n",
    "      labels: [P] Tensor, ground truth labels (between 0 and C - 1)\n",
    "      only_present: average only on classes present in ground truth\n",
    "    \"\"\"\n",
    "    C = probas.size(1)\n",
    "    losses = []\n",
    "    for c in range(C):\n",
    "        fg = (labels == c).float() # foreground for class c\n",
    "        if only_present and fg.sum() == 0:\n",
    "            continue\n",
    "        errors = (Variable(fg) - probas[:, c]).abs()\n",
    "        errors_sorted, perm = torch.sort(errors, 0, descending=True)\n",
    "        perm = perm.data\n",
    "        fg_sorted = fg[perm]\n",
    "        losses.append(torch.dot(errors_sorted, Variable(lovasz_grad(fg_sorted))))\n",
    "    return mean(losses)\n",
    "\n",
    "def flatten_probas(probas, labels, ignore=None):\n",
    "    \"\"\"\n",
    "    Flattens predictions in the batch\n",
    "    \"\"\"\n",
    "    B, C, H, W = probas.size()\n",
    "    probas = probas.permute(0, 2, 3, 1).contiguous().view(-1, C)  # B * H * W, C = P, C\n",
    "    labels = labels.view(-1)\n",
    "    if ignore is None:\n",
    "        return probas, labels\n",
    "    valid = (labels != ignore)\n",
    "    vprobas = probas[valid.nonzero().squeeze()]\n",
    "    vlabels = labels[valid]\n",
    "    return vprobas, vlabels\n",
    "\n",
    "def xloss(logits, labels, ignore=None):\n",
    "    \"\"\"\n",
    "    Cross entropy loss\n",
    "    \"\"\"\n",
    "    return F.cross_entropy(logits, Variable(labels), ignore_index=255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3sw_8EnH5dmq"
   },
   "outputs": [],
   "source": [
    "# HELPER FUNCTIONS\n",
    "\n",
    "def mean(l, ignore_nan=False, empty=0):\n",
    "    \"\"\"\n",
    "    nanmean compatible with generators.\n",
    "    \"\"\"\n",
    "    l = iter(l)\n",
    "    if ignore_nan:\n",
    "        l = ifilterfalse(np.isnan, l)\n",
    "    try:\n",
    "        n = 1\n",
    "        acc = next(l)\n",
    "    except StopIteration:\n",
    "        if empty == 'raise':\n",
    "            raise ValueError('Empty mean')\n",
    "        return empty\n",
    "    for n, v in enumerate(l, 2):\n",
    "        acc += v\n",
    "    if n == 1:\n",
    "        return acc\n",
    "    return acc / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if YADSPH:\n",
    "    train_df = pd.read_csv(f'{DATASET_PATH}/meta_sz_{PARAMS[\"image_size\"]}.csv')\n",
    "else:\n",
    "    train_df = pd.read_csv(f'{DATA_PATH}/train_meta_{PARAMS[\"image_size\"]}.csv')\n",
    "display(train_df.head())\n",
    "if DEBUG:\n",
    "    train_df = train_df.sample(100)\n",
    "df_train_img = pd.read_csv(f'{DATA_PATH}/train_image_level.csv')\n",
    "df_train_sty = pd.read_csv(f'{DATA_PATH}/train_study_level.csv')\n",
    "if YADSPH:\n",
    "    train_df['img'] = train_df['image_id'].apply(lambda x: ''.join([x, '.jpg']))\n",
    "    train_df.rename(columns={'dim1': 'dim_x', 'dim0': 'dim_y'}, inplace=True)\n",
    "    train_df['id'] = train_df['img'].apply(lambda x: x.split('/')[-1].replace('.jpg', '_image'))\n",
    "else:\n",
    "    train_df['id'] = train_df['img'].apply(lambda x: x.split('/')[-1].replace('.png', '_image'))\n",
    "df_train_sty['StudyInstanceUID'] = df_train_sty['id'].apply(lambda x: x.replace('_study', ''))\n",
    "del df_train_sty['id']\n",
    "df_train_img = df_train_img.merge(df_train_sty, on='StudyInstanceUID')\n",
    "train_df = df_train_img.merge(train_df, on='id')\n",
    "train_df['None Opacity'] = train_df['boxes'].isnull()\n",
    "display(train_df.head())\n",
    "classes = [\n",
    "    'Negative for Pneumonia',\n",
    "    'Typical Appearance', \n",
    "    'Indeterminate Appearance', \n",
    "    'Atypical Appearance'\n",
    "]\n",
    "train_df['mc_target'] = train_df.apply(lambda x: np.argmax(x[classes]), axis=1)\n",
    "print(train_df.shape)\n",
    "display(train_df.head())\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print(f'time elapsed: {elapsed_time // 60:.0f} min {elapsed_time % 60:.0f} sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bsize = min(6, PARAMS['train_bs'])\n",
    "fig, axes = plt.subplots(figsize=(16, 4), nrows=1, ncols=bsize)\n",
    "for j in range(bsize):\n",
    "    img = cv2.imread(f'{IMGS_PATH}/{train_df[\"img\"][j]}')\n",
    "    axes[j].imshow(img)\n",
    "    axes[j].set_title(train_df['img'][j])\n",
    "    axes[j].axis('off')\n",
    "plt.show()\n",
    "print('min max image', np.min(img), np.max(img))\n",
    "fig, axes = plt.subplots(figsize=(16, 4), nrows=1, ncols=bsize)\n",
    "for j in range(bsize):\n",
    "    img = cv2.imread(f'{MASKS_PATH}/{train_df[\"img\"][j]}')\n",
    "    axes[j].imshow(img)\n",
    "    axes[j].set_title(train_df['img'][j])\n",
    "    axes[j].axis('off')\n",
    "plt.show()\n",
    "print('min max mask', np.min(img), np.max(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "daDIur9i5g1d"
   },
   "outputs": [],
   "source": [
    "train_aug =  A.Compose([\n",
    "    A.OneOf([\n",
    "        A.RandomBrightness(limit=.2, p=1), \n",
    "        A.RandomContrast(limit=.2, p=1), \n",
    "    ], p=.5),\n",
    "    A.Blur(blur_limit=3, p=.25),\n",
    "    A.OneOf([\n",
    "        A.GaussNoise(0.002, p=.5),\n",
    "        A.augmentations.geometric.transforms.Affine(p=.5),\n",
    "    ], p=.25),\n",
    "    A.OneOf([\n",
    "        A.ElasticTransform(alpha=120, sigma=120 * .05, alpha_affine=120 * .03, p=.5),\n",
    "        A.GridDistortion(p=.5),\n",
    "        A.OpticalDistortion(distort_limit=2, shift_limit=.5, p=1)                  \n",
    "    ], p=.25),\n",
    "    A.RandomRotate90(p=.5),\n",
    "    A.HorizontalFlip(p=.5),\n",
    "    A.VerticalFlip(p=.5),\n",
    "    A.Cutout(num_holes=10, \n",
    "             max_h_size=int(.05 * PARAMS['image_size']), \n",
    "             max_w_size=int(.05 * PARAMS['image_size']), \n",
    "             p=.25),\n",
    "    A.ShiftScaleRotate(p=.25),\n",
    "    ToTensorV2(p=1)\n",
    "])\n",
    "valid_aug = A.Compose([ToTensorV2(p=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ywiW2SXZ5guq"
   },
   "outputs": [],
   "source": [
    "class StudyDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, df, target='mc_target', tab_data=None, aug=None):\n",
    "        super().__init__()\n",
    "        self.df = df \n",
    "        self.aug = aug \n",
    "        self.target = target\n",
    "        self.tab_data = tab_data\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = cv2.imread(f'{IMGS_PATH}/{self.df[\"img\"][idx]}')\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  \n",
    "        mask = cv2.imread(f'{MASKS_PATH}/{self.df[\"img\"][idx]}')\n",
    "        mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY) \n",
    "        if self.aug:\n",
    "            augmented = self.aug(image=image, mask=mask)\n",
    "            image = augmented['image'] / 255\n",
    "            mask = augmented['mask'] / 255\n",
    "        else:\n",
    "            image = torch.from_numpy(image).float()\n",
    "            image = image.permute(2, 1, 0) / 255\n",
    "            mask = mask / 255\n",
    "        target = self.df[self.target][idx]\n",
    "        if self.tab_data:\n",
    "            tab_data = self.df[['modality','sex','body_part']].values\n",
    "            tab_data = tab_data[idx]\n",
    "            tab_data = torch.tensor(tab_data)\n",
    "            return image, target, mask, tab_data \n",
    "        else:\n",
    "            return image, target, mask\n",
    "    \n",
    "dataset_show = StudyDataset(\n",
    "    df=train_df,\n",
    "    aug=train_aug\n",
    ")\n",
    "img_show, lbl_show, mask_show = dataset_show.__getitem__(2)\n",
    "img_show = img_show.numpy().transpose([1, 2, 0])\n",
    "img_show = np.clip(img_show, 0, 1)\n",
    "plt.imshow(img_show)\n",
    "plt.title('image, target ' + str(lbl_show))\n",
    "plt.show()\n",
    "plt.imshow(mask_show)\n",
    "plt.title('mask, target ' + str(lbl_show))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0XnaIFnx5gp3"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_classes=4, tab_flag=False):\n",
    "        super(Net, self).__init__()\n",
    "        e = timm.create_model(PARAMS['model_arch'], pretrained=True)\n",
    "        self.b0 = nn.Sequential(\n",
    "            e.conv_stem,\n",
    "            e.bn1,\n",
    "            e.act1\n",
    "        )\n",
    "        self.b1 = e.blocks[0]\n",
    "        self.b2 = e.blocks[1]\n",
    "        self.b3 = e.blocks[2]\n",
    "        self.b4 = e.blocks[3]\n",
    "        self.b5 = e.blocks[4]\n",
    "        self.b6 = e.blocks[5]\n",
    "        self.b7 = e.blocks[6]\n",
    "        self.b8 = nn.Sequential(\n",
    "            e.conv_head, \n",
    "            e.bn2,\n",
    "            e.act2\n",
    "        )\n",
    "        self.final_eff_layer = nn.Linear(e.classifier.in_features, 1000)\n",
    "        self.mask = nn.Sequential(\n",
    "            nn.Conv2d(176, 160, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(160),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(160, 160, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(160),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(160, 1, kernel_size=1, padding=0),\n",
    "        )\n",
    "        self.tab_flag = tab_flag\n",
    "        if self.tab_flag:\n",
    "            # Tab layers \n",
    "            num_features = 3\n",
    "            self.hidden_size = [10, 6] \n",
    "            self.batch_norm1 = nn.BatchNorm1d(num_features)\n",
    "            self.linear1 = nn.Linear(num_features, self.hidden_size[0])\n",
    "            self.batch_norm2 = nn.BatchNorm1d(self.hidden_size[0])\n",
    "            self.linear2 = nn.Linear(self.hidden_size[0], self.hidden_size[1])\n",
    "            # FINAL LAYER \n",
    "            self.final = nn.Linear(1006, n_classes)\n",
    "        else:\n",
    "            self.final = nn.Linear(1000, n_classes)\n",
    "\n",
    "    # @torch.cuda.amp.autocast()\n",
    "    def forward(self, image, tab_data=None):\n",
    "        # Image layers\n",
    "        batch_size = len(image)\n",
    "        x = 2 * image - 1    \n",
    "        x = self.b0(x) \n",
    "        x = self.b1(x) \n",
    "        x = self.b2(x) \n",
    "        x = self.b3(x) \n",
    "        x = self.b4(x)\n",
    "        x = self.b5(x) \n",
    "        # ============ #\n",
    "        mask = self.mask(x)\n",
    "        # ============ #\n",
    "        x = self.b6(x) \n",
    "        x = self.b7(x) \n",
    "        x = self.b8(x)\n",
    "        x = F.adaptive_avg_pool2d(x, 1).reshape(batch_size, -1)\n",
    "        x = self.final_eff_layer(x)\n",
    "        if tab_data:\n",
    "            # TAB layers \n",
    "            y = self.batch_norm1(tab_data)\n",
    "            y = F.relu(self.linear1(y))\n",
    "            y = self.batch_norm2(y)\n",
    "            y = F.relu(self.linear2(y))\n",
    "            # Final Layers \n",
    "            x = torch.cat((x, y), dim=1)  # Concatenating image feats + tab feats \n",
    "        x = F.relu(x)\n",
    "        logit = self.final(x)\n",
    "        return logit, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mUID25fp5gnv"
   },
   "outputs": [],
   "source": [
    "def custom_map(target, pred):\n",
    "    c1 = [0] * len(target)\n",
    "    c2 = [0] * len(target)\n",
    "    c3 = [0] * len(target)\n",
    "    c4 = [0] * len(target)\n",
    "    t1 = [0] * len(target)\n",
    "    t2 = [0] * len(target)\n",
    "    t3 = [0] * len(target)\n",
    "    t4 = [0] * len(target)\n",
    "    for i in range(len(pred)):\n",
    "        c1[i] = pred[i][0]\n",
    "        c2[i] = pred[i][1]\n",
    "        c3[i] = pred[i][2]\n",
    "        c4[i] = pred[i][3]\n",
    "        if target[i] == 0:\n",
    "            t1[i] = 1\n",
    "        else:\n",
    "            t1[i] = 0\n",
    "        if target[i] == 1:\n",
    "            t2[i] = 1\n",
    "        else:\n",
    "            t2[i] = 0\n",
    "        if target[i] == 2:\n",
    "            t3[i] = 1\n",
    "        else:\n",
    "            t3[i] = 0 \n",
    "        if target[i] == 3:\n",
    "            t4[i] = 1 \n",
    "        else:\n",
    "            t4[i] = 0\n",
    "    mean_ap = (\n",
    "        average_precision_score(t1, c1) + \n",
    "        average_precision_score(t2, c2) +\n",
    "        average_precision_score(t3, c3) + \n",
    "        average_precision_score(t4, c4)\n",
    "    ) / 4\n",
    "    return mean_ap * (2 / 3)\n",
    "        \n",
    "def custom_map2(preds, targs):\n",
    "    return np.mean([\n",
    "        average_precision_score(targs==i, preds[:, i]) for i in range(4)\n",
    "    ]) * 2 / 3  \n",
    "\n",
    "class FocalCosineLoss(nn.Module):\n",
    "    \n",
    "    def __init__(self, alpha=1, gamma=2, xent=.1):\n",
    "        super(FocalCosineLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.xent = xent\n",
    "        self.y = torch.Tensor([1]).cuda()\n",
    "\n",
    "    def forward(self, input, target, reduction=\"mean\"):\n",
    "        cosine_loss = F.cosine_embedding_loss(\n",
    "            input, \n",
    "            F.one_hot(target, num_classes=input.size(-1)), \n",
    "            self.y, \n",
    "            reduction=reduction\n",
    "        )\n",
    "        cent_loss = F.cross_entropy(\n",
    "            F.normalize(input), \n",
    "            target, \n",
    "            reduce=False\n",
    "        )\n",
    "        pt = torch.exp(-cent_loss)\n",
    "        focal_loss = self.alpha * (1 - pt) ** self.gamma * cent_loss\n",
    "        if reduction == 'mean':\n",
    "            focal_loss = torch.mean(focal_loss)\n",
    "        return cosine_loss + self.xent * focal_loss\n",
    "\n",
    "def elo_loss(logits, y, reduction='mean'):\n",
    "    \"\"\"\n",
    "    https://towardsdatascience.com/explicit-auc-maximization-70beef6db14e\n",
    "    \"\"\"\n",
    "    # reduction mean, sum ...\n",
    "    losses = [] \n",
    "    class_ids = y.unique()    \n",
    "    for i in class_ids:\n",
    "        class_logits = logits[:, i.item()]\n",
    "        class_targs = (y == i).float()\n",
    "        mask = (class_targs.unsqueeze(1) * (1 - class_targs.unsqueeze(0))).bool()\n",
    "        class_loss = -torch.sigmoid(class_logits.unsqueeze(1) - class_logits.unsqueeze(0))[mask].mean()\n",
    "        losses.append(class_loss)\n",
    "    loss = torch.stack(losses)\n",
    "    if reduction == 'mean': return torch.mean(loss)\n",
    "    if reduction == 'sum':  return torch.sum(loss)\n",
    "    \n",
    "def symmetric_lovasz(outputs, targets):\n",
    "    return .5 * (lovasz_hinge(outputs, targets) + \n",
    "                 lovasz_hinge(-outputs, 1 - targets)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qvp4m_Sj5glT"
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(model, trainloader, optimizer, criterion,\n",
    "                    epoch, device, scheduler=None):\n",
    "    model.train()\n",
    "    t = time.time()\n",
    "    scaler = GradScaler()\n",
    "    accum_iter = PARAMS['accum_iter']\n",
    "    final_loss = 0\n",
    "    all_targets = []\n",
    "    all_preds = []\n",
    "    all_preds_ = []\n",
    "    soft = nn.Softmax()\n",
    "    bce = nn.BCEWithLogitsLoss()\n",
    "    pbar = tqdm(trainloader, total=len(trainloader))\n",
    "    for i, (image, target, mask) in enumerate(pbar):\n",
    "        image = image.to(device, dtype=torch.float32)\n",
    "        mask = mask.to(device, dtype=torch.float32)\n",
    "        mask = mask.unsqueeze(1)\n",
    "        mask = F.interpolate(mask, size=(32, 32), mode='bilinear', align_corners=False)\n",
    "        if PARAMS['amp']:\n",
    "            with autocast():\n",
    "                if PARAMS['n_classes'] > 1:\n",
    "                    target = target.to(device, dtype=torch.long)\n",
    "                    optimizer.zero_grad()\n",
    "                    logits, pred_mask = model(image)\n",
    "                    loss1 = criterion(logits, target)\n",
    "                    loss2 = bce(pred_mask, mask)\n",
    "                    loss3 = symmetric_lovasz(pred_mask, mask) \n",
    "                    probs = torch.softmax(logits, 1)\n",
    "                else:\n",
    "                    target = target.to(device).float()\n",
    "                    target = target.unsqueeze(1)\n",
    "                    optimizer.zero_grad()\n",
    "                    logits, pred_mask = model(image)\n",
    "                    loss1 = criterion(logits, target)\n",
    "                    loss2 = bce(pred_mask, mask)\n",
    "                    loss3 = symmetric_lovasz(pred_mask , mask)\n",
    "                    probs = nn.Sigmoid()(logits)\n",
    "                sum_loss = (loss1 + loss2 + loss3) / 3\n",
    "                # normalize loss to account for batch accumulation\n",
    "                sum_loss /= accum_iter\n",
    "                scaler.scale(sum_loss).backward()\n",
    "                # weights update\n",
    "                if ((i + 1) % accum_iter == 0) or (i + 1 == len(trainloader)):\n",
    "                    scaler.step(optimizer)\n",
    "                    scaler.update()\n",
    "                    optimizer.zero_grad()\n",
    "                    if scheduler is not None:\n",
    "                        scheduler.step()\n",
    "                final_loss += loss1.detach().item()\n",
    "                all_targets.extend(target.cpu().detach().numpy().tolist())\n",
    "                all_preds.extend(probs.cpu().detach().numpy().tolist())\n",
    "                all_preds_.extend(torch.round(probs).cpu().detach().numpy().tolist())\n",
    "            pbar.set_description(f'epoch: {epoch + 1}, loss: {loss1.item():.3f}')\n",
    "        else:\n",
    "            print('NOT IMPLEMENTED'); break\n",
    "    if PARAMS['n_classes'] > 1:\n",
    "        return final_loss / len(trainloader), roc_auc_score(\n",
    "            all_targets, \n",
    "            all_preds,\n",
    "            multi_class=\"ovo\",\n",
    "            average=\"macro\"\n",
    "        ), roc_auc_score(\n",
    "            all_targets, \n",
    "            all_preds,\n",
    "            multi_class=\"ovr\",\n",
    "            average=\"macro\"\n",
    "        ), custom_map(all_targets, all_preds)\n",
    "    else:\n",
    "        return final_loss / len(trainloader), roc_auc_score(\n",
    "            all_targets , \n",
    "            all_preds\n",
    "        ), average_precision_score(\n",
    "            all_targets,\n",
    "            all_preds\n",
    "        ), accuracy_score(all_targets , all_preds_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ev2hRsv85gjS"
   },
   "outputs": [],
   "source": [
    "def validate_one_epoch(model, validloader, criterion, epoch, device):\n",
    "    t = time.time()\n",
    "    model.eval()\n",
    "    final_loss = 0.0\n",
    "    all_targets = []\n",
    "    all_preds = []\n",
    "    all_preds_ = []\n",
    "    all_preds_cl = []\n",
    "    soft = nn.Softmax()\n",
    "    pbar = tqdm(validloader, total=len(validloader))\n",
    "    for i, (image, target, mask) in enumerate(pbar):\n",
    "        image = image.to(device, dtype=torch.float32)\n",
    "        mask = mask.to(device, dtype=torch.float32)\n",
    "        mask = mask.unsqueeze(1)\n",
    "        if PARAMS['n_classes'] > 1:\n",
    "            target = target.to(device, dtype=torch.long)\n",
    "            logits, pred_mask = model(image)\n",
    "            loss = criterion(logits, target)\n",
    "            probs = torch.softmax(logits, 1)\n",
    "            final_loss += loss.detach().item()\n",
    "            all_targets.extend(target.cpu().detach().numpy().tolist())\n",
    "            all_preds.extend(probs.cpu().detach().numpy().tolist())\n",
    "            all_preds_cl.extend(torch.argmax(logits, 1).cpu().detach().numpy().tolist())\n",
    "        else:\n",
    "            target = target.to(device).float()\n",
    "            target = target.unsqueeze(1)\n",
    "            logits, pred_mask = model(image)\n",
    "            loss = criterion(logits, target)\n",
    "            probs = nn.Sigmoid()(logits)\n",
    "            final_loss += loss.detach().item()\n",
    "            all_targets.extend(target.cpu().detach().numpy().tolist())\n",
    "            all_preds.extend(probs.cpu().detach().numpy().tolist())\n",
    "            all_preds_.extend(torch.round(probs).cpu().detach().numpy().tolist())\n",
    "        pbar.set_description(f'epoch: {epoch + 1}, loss: {loss.item():.3f}')\n",
    "    if PARAMS['n_classes'] > 1:\n",
    "        return final_loss / len(validloader), roc_auc_score(\n",
    "            all_targets, \n",
    "            all_preds,\n",
    "            multi_class=\"ovo\",\n",
    "            average=\"macro\"\n",
    "        ), roc_auc_score(\n",
    "            all_targets, \n",
    "            all_preds, \n",
    "            multi_class=\"ovr\", \n",
    "            average=\"macro\"\n",
    "        ), custom_map(all_targets, all_preds), accuracy_score(\n",
    "            all_targets,\n",
    "            all_preds_cl\n",
    "        ), precision_score(\n",
    "            all_targets,\n",
    "            all_preds_cl,\n",
    "            average='macro'\n",
    "        )\n",
    "    else:\n",
    "        return final_loss  /len(validloader), roc_auc_score(\n",
    "            all_targets, \n",
    "            all_preds), average_precision_score(\n",
    "            all_targets,\n",
    "            all_preds\n",
    "        ), accuracy_score(all_targets, all_preds_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "naLMoXzx5gg1"
   },
   "outputs": [],
   "source": [
    "def engine(splits, target='Negative for Pneumonia'):\n",
    "    mean_ap = 0.0\n",
    "    cnt = 0\n",
    "    skf  = StratifiedKFold(n_splits=splits)\n",
    "    for fold, (train_idx , valid_idx) in enumerate(skf.split(\n",
    "        train_df, \n",
    "        y=train_df[target].tolist()\n",
    "    )):\n",
    "        print('=' * 48)\n",
    "        print('=' * 20, f'FOLD {fold}', '=' * 20)\n",
    "        print('=' * 48)\n",
    "        print(f'training for \"{target}\" class',\n",
    "              f'\\ntrain len: {len(train_idx)} | val len: {len(valid_idx)}')\n",
    "        print('=' * 48)\n",
    "        model = Net(n_classes=PARAMS['n_classes'])\n",
    "        train_data = train_df.iloc[train_idx, :].reset_index(drop=True)\n",
    "        valid_data = train_df.iloc[valid_idx, :].reset_index(drop=True)\n",
    "        train_dataset = StudyDataset(train_data, target, aug=train_aug)\n",
    "        valid_dataset = StudyDataset(valid_data, target, aug=valid_aug)\n",
    "        trainloader = DataLoader(\n",
    "            train_dataset,\n",
    "            shuffle=True,\n",
    "            pin_memory=True,\n",
    "            num_workers=PARAMS['n_workers'],\n",
    "            batch_size=PARAMS['train_bs'],\n",
    "            drop_last=False\n",
    "        )\n",
    "        validloader = DataLoader(\n",
    "            valid_dataset,\n",
    "            shuffle=False,\n",
    "            pin_memory=True,\n",
    "            num_workers=PARAMS['n_workers'],\n",
    "            batch_size=PARAMS['valid_bs'],\n",
    "            drop_last=False\n",
    "        )\n",
    "        model.to(PARAMS['device'])\n",
    "        optimizer = optim.AdamW(model.parameters(), PARAMS['init_lr']) \n",
    "        if PARAMS['n_classes'] > 1:\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "        else:\n",
    "            criterion = nn.BCEWithLogitsLoss()\n",
    "        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, PARAMS['t_max'])\n",
    "        validation_ap = 0\n",
    "        validation_roc_auc = 0\n",
    "        best_ep = 0\n",
    "        epochs_no_improve = 0\n",
    "        for epoch in range(PARAMS['epochs']):\n",
    "            if PARAMS['n_classes'] > 1:\n",
    "                train_loss, train_roc_auc_macro_ovo, \\\n",
    "                train_roc_auc_macro_ovr, train_map = train_one_epoch(\n",
    "                    model,\n",
    "                    trainloader,\n",
    "                    optimizer,\n",
    "                    criterion,\n",
    "                    epoch,\n",
    "                    PARAMS['device'],\n",
    "                    scheduler\n",
    "                )\n",
    "                with torch.no_grad():\n",
    "                    valid_loss, valid_roc_auc_macro_ovo, valid_roc_auc_macro_ovr, \\\n",
    "                    val_map, val_acc, val_pre = validate_one_epoch(\n",
    "                        model,\n",
    "                        validloader,\n",
    "                        criterion, \n",
    "                        epoch,\n",
    "                        PARAMS['device']\n",
    "                    )\n",
    "                content = ''.join([\n",
    "                    f'{time.ctime()} epoch {epoch} | ',\n",
    "                    f'train loss {train_loss:.4f}, val loss {valid_loss:.4f} | ',\n",
    "                    f'train roc auc macro ovo {train_roc_auc_macro_ovo:.4f}, '\n",
    "                    f'val roc auc macro ovo {valid_roc_auc_macro_ovo:.4f} | ',\n",
    "                    f'train_roc_auc_macro_ovr {train_roc_auc_macro_ovr:.4f}, ',\n",
    "                    f'valid roc auc macro ovr {valid_roc_auc_macro_ovr:.4f} | '\n",
    "                    f'train_map {train_map:.4f}, val map {val_map:.4f} | ',\n",
    "                    f'val acc {val_acc:.4f}, val precision {val_pre:.4f}'\n",
    "                ])\n",
    "                print(content)\n",
    "            else:\n",
    "                train_loss, train_roc_auc, train_ap, train_acc = train_one_epoch(\n",
    "                    model,\n",
    "                    trainloader,\n",
    "                    optimizer,\n",
    "                    criterion,\n",
    "                    epoch,\n",
    "                    PARAMS['device'],\n",
    "                    scheduler\n",
    "                )\n",
    "                with torch.no_grad():\n",
    "                    valid_loss, valid_roc_auc, val_ap, valid_acc = validate_one_epoch(\n",
    "                        model,\n",
    "                        validloader,\n",
    "                        criterion,\n",
    "                        epoch,\n",
    "                        PARAMS['device']\n",
    "                    )\n",
    "                content = ''.join([\n",
    "                    f'{time.ctime()} epoch {epoch} | ',\n",
    "                    f'train loss {train_loss:.4f}, val loss {valid_loss:.4f} | ',\n",
    "                    f'train roc auc {train_roc_auc:.4f}, '\n",
    "                    f'val roc auc {valid_roc_auc:.4f} | ',\n",
    "                    f'train AP {train_ap:.4f}, valid AP {val_ap:.4f} | '\n",
    "                    f'train accuracy {train_acc:.4f}, val accuracy {valid_acc:.4f}'\n",
    "                ])\n",
    "            with open('{}/log_{}.txt'.format(MDLS_PATH, fold), 'a') as appender:\n",
    "                appender.write(content + '\\n')\n",
    "            if PARAMS['n_classes'] > 1:              \n",
    "                if val_map > validation_ap:\n",
    "                    print(f'mAP val improves: {validation_ap} -> {val_map}')\n",
    "                    validation_ap = val_map\n",
    "                    best_ep = epoch\n",
    "                    torch.save(\n",
    "                        model.state_dict(),\n",
    "                        f\"{MDLS_PATH}/model_best_fold_{fold}.pth\"\n",
    "                    )\n",
    "                    epochs_no_improve = 0\n",
    "                else:\n",
    "                    epochs_no_improve += 1\n",
    "            else:              \n",
    "                if valid_roc_auc > validation_roc_auc:\n",
    "                    print(f'val roc auc improves: {validation_roc_auc} -> {valid_roc_auc}')\n",
    "                    validation_roc_auc = valid_roc_auc\n",
    "                    best_ep = epoch\n",
    "                    torch.save(\n",
    "                        model.state_dict(),\n",
    "                        f\"{MDLS_PATH}/model_best_fold_{fold}.pth\"\n",
    "                    )\n",
    "                    epochs_no_improve = 0\n",
    "                else:\n",
    "                    epochs_no_improve += 1\n",
    "            if epochs_no_improve >= PARAMS['patience']:\n",
    "                print('no improve for', epochs_no_improve, 'epochs | early stopping')\n",
    "                break\n",
    "        torch.save(\n",
    "            model.state_dict(),\n",
    "            f\"{MDLS_PATH}/model_final_fold_{fold}.pth\"\n",
    "        )\n",
    "        if PARAMS['n_classes'] > 1:\n",
    "            with open('{}/log_{}.txt'.format(MDLS_PATH, fold), 'a') as appender:\n",
    "                appender.write(f'\\nbest val mAP: {validation_ap:.3f} | best epoch {best_ep}')\n",
    "        else:\n",
    "            with open('{}/log_{}.txt'.format(MDLS_PATH, fold), 'a') as appender:\n",
    "                appender.write(f'\\nbest val roc auc: {validation_roc_auc:.3f} | best epoch {best_ep}')            \n",
    "        del model, train_data, valid_data, train_dataset, valid_dataset, trainloader, validloader\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 116,
     "referenced_widgets": [
      "79b683d952e44a54ba500c3638ac71b5",
      "19edfd65ad8e41f8ac45f6fc1ed5d9b3",
      "4ac697de64324dd9a94576284d8d569f",
      "8497ccb2650a4402a1c00cd75b7945a4",
      "dd995cd63af74fdf92fff9a834d3e84a",
      "3d246fe0270944c28ef2ac83c9d6b5a2",
      "831a9b044aaa4551a089aa2cfa9baf16",
      "7389570a651f43009d1dee5b86c134b7"
     ]
    },
    "id": "pxIO6KYt5gew",
    "outputId": "276369c7-5f0a-4c48-9214-cf0b3469f2a8"
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    if PARAMS['n_classes'] > 1:\n",
    "        engine(PARAMS['splits'], 'mc_target')\n",
    "    else:\n",
    "        engine(PARAMS['splits'], 'None Opacity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "effv2_L_[ IMTAB ].ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Orange Python 3",
   "language": "python",
   "name": "orange"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "19edfd65ad8e41f8ac45f6fc1ed5d9b3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3d246fe0270944c28ef2ac83c9d6b5a2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4ac697de64324dd9a94576284d8d569f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "Epoch:1, loss: 1.399:  65%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3d246fe0270944c28ef2ac83c9d6b5a2",
      "max": 692,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_dd995cd63af74fdf92fff9a834d3e84a",
      "value": 453
     }
    },
    "7389570a651f43009d1dee5b86c134b7": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "79b683d952e44a54ba500c3638ac71b5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4ac697de64324dd9a94576284d8d569f",
       "IPY_MODEL_8497ccb2650a4402a1c00cd75b7945a4"
      ],
      "layout": "IPY_MODEL_19edfd65ad8e41f8ac45f6fc1ed5d9b3"
     }
    },
    "831a9b044aaa4551a089aa2cfa9baf16": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8497ccb2650a4402a1c00cd75b7945a4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7389570a651f43009d1dee5b86c134b7",
      "placeholder": "",
      "style": "IPY_MODEL_831a9b044aaa4551a089aa2cfa9baf16",
      "value": " 453/692 [06:24&lt;03:25,  1.16it/s]"
     }
    },
    "dd995cd63af74fdf92fff9a834d3e84a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
