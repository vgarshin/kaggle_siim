{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import yaml\n",
    "import time\n",
    "import json\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GroupKFold, StratifiedKFold\n",
    "from tqdm.notebook import tqdm\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from IPython.display import Image, clear_output\n",
    "from collections import Counter\n",
    "from ensemble_boxes import *\n",
    "import copy\n",
    "import os.path as osp\n",
    "import mmcv\n",
    "import mmdet\n",
    "import numpy as np\n",
    "import albumentations as A\n",
    "from mmdet.datasets.builder import DATASETS\n",
    "from mmdet.datasets.custom import CustomDataset\n",
    "from mmcv import Config\n",
    "from mmdet.apis import set_random_seed\n",
    "from mmdet.apis import inference_detector, init_detector, show_result_pyplot\n",
    "from mmdet.datasets import build_dataset\n",
    "from mmdet.models import build_detector\n",
    "from mmdet.apis import train_detector\n",
    "print(mmdet.__version__)\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VER = 'v0'\n",
    "TEST = False\n",
    "DEBUG = False\n",
    "PARAMS = {\n",
    "    'version': VER,\n",
    "    'folds': 4,\n",
    "    'val_fold': 0,\n",
    "    'img_size': 640,\n",
    "    'batch_size': 4,\n",
    "    'epochs': 10,\n",
    "    'seed': 2020,\n",
    "    'iou_th': .6,\n",
    "    # 0\n",
    "    #'config': 'faster_rcnn/faster_rcnn_r50_caffe_fpn_mstrain_1x_coco.py',    \n",
    "    # 1\n",
    "    #'config': 'faster_rcnn/faster_rcnn_r50_caffe_fpn_mstrain_3x_coco.py',\n",
    "    #'checkpoint': 'mask_rcnn_r50_caffe_fpn_mstrain-poly_3x_coco_bbox_mAP-0.408__segm_mAP-0.37_20200504_163245-42aa3d00.pth',\n",
    "    # 2\n",
    "    'config': 'vfnet/vfnet_r50_fpn_mdconv_c3-c5_mstrain_2x_coco.py',\n",
    "    'checkpoint': 'vfnet_r50_fpn_mdconv_c3-c5_mstrain_2x_coco_20201027pth-6879c318.pth',\n",
    "    # 3\n",
    "    #'config': 'vfnet/vfnet_r101_fpn_mdconv_c3-c5_mstrain_2x_coco.py',\n",
    "    #'checkpoint': 'vfnet_r101_fpn_mdconv_c3-c5_mstrain_2x_coco_20201027pth-7729adb5.pth',\n",
    "    #'split_mkf': True,\n",
    "    'comments': ''\n",
    "}\n",
    "DATA_PATH = '/u01/mrorange/siim/data'\n",
    "WRK_DIR = f'/u01/mrorange/siim/mmdetection'\n",
    "IMGS_PATH = f'{DATA_PATH}/train_{PARAMS[\"img_size\"]}'\n",
    "MDLS_PATH = f'/u01/mrorange/siim/models_mmdet_{VER}'\n",
    "if not os.path.exists(MDLS_PATH):\n",
    "    os.mkdir(MDLS_PATH)\n",
    "with open(f'{MDLS_PATH}/params.json', 'w') as file:\n",
    "    json.dump(PARAMS, file)\n",
    "    \n",
    "def seed_all(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "seed_all(PARAMS['seed'])\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TEST: \n",
    "    !mkdir {WRK_DIR}/checkpoints\n",
    "    !wget -c http://download.openmmlab.com/mmdetection/v2.0/mask_rcnn/mask_rcnn_r50_caffe_fpn_mstrain-poly_3x_coco/mask_rcnn_r50_caffe_fpn_mstrain-poly_3x_coco_bbox_mAP-0.408__segm_mAP-0.37_20200504_163245-42aa3d00.pth \\\n",
    "          -O {WRK_DIR}/checkpoints/mask_rcnn_r50_caffe_fpn_mstrain-poly_3x_coco_bbox_mAP-0.408__segm_mAP-0.37_20200504_163245-42aa3d00.pth\n",
    "    !wget -c https://openmmlab.oss-cn-hangzhou.aliyuncs.com/mmdetection/v2.0/vfnet/vfnet_r50_fpn_mdconv_c3-c5_mstrain_2x_coco/vfnet_r50_fpn_mdconv_c3-c5_mstrain_2x_coco_20201027pth-6879c318.pth \\\n",
    "        -O {WRK_DIR}/checkpoints/vfnet_r50_fpn_mdconv_c3-c5_mstrain_2x_coco_20201027pth-6879c318.pth\n",
    "    !wget -c https://openmmlab.oss-cn-hangzhou.aliyuncs.com/mmdetection/v2.0/vfnet/vfnet_r101_fpn_mdconv_c3-c5_mstrain_2x_coco/vfnet_r101_fpn_mdconv_c3-c5_mstrain_2x_coco_20201027pth-7729adb5.pth \\\n",
    "        -O {WRK_DIR}/checkpoints/vfnet_r101_fpn_mdconv_c3-c5_mstrain_2x_coco_20201027pth-7729adb5.pth\n",
    "    \n",
    "    config = f'{WRK_DIR}/configs/mask_rcnn/mask_rcnn_r50_caffe_fpn_mstrain-poly_3x_coco.py'\n",
    "    checkpoint = f'{WRK_DIR}/checkpoints/mask_rcnn_r50_caffe_fpn_mstrain-poly_3x_coco_bbox_mAP-0.408__segm_mAP-0.37_20200504_163245-42aa3d00.pth'\n",
    "    model = init_detector(config, checkpoint, device='cuda:0')\n",
    "    img = 'tomatokillers.jpg'\n",
    "    result = inference_detector(model, img)\n",
    "    show_result_pyplot(model, img, result, score_thr=.5)\n",
    "else:\n",
    "    print('no test mode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(f'{DATA_PATH}/train_meta_{PARAMS[\"img_size\"]}.csv')\n",
    "if DEBUG:\n",
    "    train_df = train_df.loc[:100]\n",
    "df_train_img = pd.read_csv(f'{DATA_PATH}/train_image_level.csv')\n",
    "df_train_sty = pd.read_csv(f'{DATA_PATH}/train_study_level.csv')\n",
    "\n",
    "train_df['id'] = train_df['img'].apply(lambda x: x.split('/')[-1].replace('.png', '_image'))\n",
    "df_train_sty['StudyInstanceUID'] = df_train_sty['id'].apply(lambda x: x.replace('_study', ''))\n",
    "del df_train_sty['id']\n",
    "df_train_img = df_train_img.merge(df_train_sty, on='StudyInstanceUID')\n",
    "train_df = df_train_img.merge(train_df, on='id')\n",
    "print(train_df.shape)\n",
    "display(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bar_plot(train_df, variable):\n",
    "    var = train_df[variable]\n",
    "    varValue = var.value_counts()\n",
    "    plt.figure(figsize = (12, 3))\n",
    "    plt.bar(varValue.index, varValue)\n",
    "    plt.xticks(varValue.index, varValue.index.values)\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.title(variable)\n",
    "    plt.show()\n",
    "    print(\"{}: \\n{}\".format(variable, varValue))\n",
    "\n",
    "train_df['target'] = 'Negative for Pneumonia'\n",
    "train_df.loc[train_df['Typical Appearance']==1, 'target'] = 'Typical Appearance'\n",
    "train_df.loc[train_df['Indeterminate Appearance']==1, 'target'] = 'Indeterminate Appearance'\n",
    "train_df.loc[train_df['Atypical Appearance']==1, 'target'] = 'Atypical Appearance'\n",
    "bar_plot(train_df, 'target') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df[~train_df.boxes.isnull()] \n",
    "train_df.reset_index(inplace=True)\n",
    "classes = [\n",
    "    'Typical Appearance', \n",
    "    'Indeterminate Appearance', \n",
    "    'Atypical Appearance'\n",
    "]\n",
    "print('classes:\\n', classes,\n",
    "      '\\nclasses labels:\\n', np.unique(train_df[classes].values, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label2color = {\n",
    "    '[1, 0, 0]': [255, 0, 0], # Typical Appearance\n",
    "    '[0, 1, 0]': [0, 255, 0], # Indeterminate Appearance\n",
    "    '[0, 0, 1]': [0, 0, 255], # Atypical Appearance\n",
    "}\n",
    "label2classes = {\n",
    "    '[1, 0, 0]': classes[0],\n",
    "    '[0, 1, 0]': classes[1],\n",
    "    '[0, 0, 1]': classes[2]\n",
    "}\n",
    "\n",
    "def plot_img(img, size=(18, 18), title='', cmap='gray'):\n",
    "    plt.figure(figsize=size)\n",
    "    plt.imshow(img, cmap=cmap)\n",
    "    plt.suptitle(title)\n",
    "    plt.show()\n",
    "\n",
    "def plot_imgs(imgs, cols=2, size=10, is_rgb=True, title='', cmap='gray', img_size=None):\n",
    "    rows = len(imgs) // cols + 1\n",
    "    fig = plt.figure(figsize=(cols * size, rows * size))\n",
    "    for i, img in enumerate(imgs):\n",
    "        if img_size is not None:\n",
    "            img = cv2.resize(img, img_size)\n",
    "        fig.add_subplot(rows, cols, i + 1)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(img, cmap=cmap)\n",
    "    plt.suptitle(title)\n",
    "    plt.axis('off')\n",
    "    \n",
    "def draw_bbox(img, box, label, color, thickness=3):   \n",
    "    alpha = .1\n",
    "    alpha_box = .4\n",
    "    overlay_bbox = img.copy()\n",
    "    overlay_text = img.copy()\n",
    "    output = img.copy()\n",
    "    text_width, text_height = cv2.getTextSize(label.upper(), cv2.FONT_HERSHEY_SIMPLEX, .6, 1)[0]\n",
    "    cv2.rectangle(overlay_bbox, \n",
    "                  (box[0], box[1]), \n",
    "                  (box[2], box[3]), \n",
    "                  color, -1)\n",
    "    cv2.addWeighted(overlay_bbox, alpha, output, 1 - alpha, 0, output)\n",
    "    cv2.rectangle(overlay_text, \n",
    "                  (box[0], box[1] - 7 - text_height), \n",
    "                  (box[0] + text_width + 2, box[1]),\n",
    "                  (0, 0, 0), -1)\n",
    "    cv2.addWeighted(overlay_text, alpha_box, output, 1 - alpha_box, 0, output)\n",
    "    cv2.rectangle(output, \n",
    "                  (box[0], box[1]), \n",
    "                  (box[2], box[3]),\n",
    "                  color, thickness)\n",
    "    cv2.putText(output, \n",
    "                label.upper(), \n",
    "                (box[0], box[1]-5),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                .6, (255, 255, 255), 1, \n",
    "                cv2.LINE_AA)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = []\n",
    "sample = train_df.sample(n=6)['img'].values\n",
    "for img_name in sample:\n",
    "    img = cv2.imread(f'{IMGS_PATH}/{img_name}')\n",
    "    imgs.append(img)\n",
    "plot_imgs(imgs, size=8, cols=len(sample), cmap=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = []\n",
    "sample = train_df.sample(n=4)['img'].values\n",
    "for img_name in sample:\n",
    "    ratio_x = PARAMS['img_size'] / train_df.loc[train_df['img'] == img_name, 'dim_x'].values[0]\n",
    "    ratio_y = PARAMS['img_size'] / train_df.loc[train_df['img'] == img_name, 'dim_y'].values[0]\n",
    "    boxes = train_df.loc[train_df['img'] == img_name, 'boxes'].values[0]\n",
    "    boxes = json.loads(boxes.replace('\\'', '\\\"'))\n",
    "    boxes = [[int(box['x'] * ratio_x), \n",
    "              int(box['y'] * ratio_y), \n",
    "              int((box['x'] + box['width']) * ratio_x), \n",
    "              int((box['y'] + box['height']) * ratio_y)]\n",
    "             for box in boxes]\n",
    "    img_labels = train_df.loc[train_df['img'] == img_name, classes].values[0]\n",
    "    img_labels = [str(img_labels.tolist())] * len(boxes)\n",
    "    img = cv2.imread(f'{IMGS_PATH}/{img_name}')\n",
    "    for label_id, box in zip(img_labels, boxes):\n",
    "        color = label2color[label_id]\n",
    "        img = draw_bbox(\n",
    "            img, \n",
    "            list(np.int_(box)), \n",
    "            label2classes[label_id], \n",
    "            label2color[label_id]\n",
    "        )\n",
    "    imgs.append(img)\n",
    "plot_imgs(imgs, size=8, cols=4, cmap=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf  = StratifiedKFold(n_splits=PARAMS['folds'])\n",
    "train_df['fold'] = -1\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(train_df, y=train_df.target)):\n",
    "    train_df.loc[val_idx, 'fold'] = fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.loc[train_df.fold == 0, 'target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.loc[train_df.fold != 0, 'target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = PARAMS['val_fold']\n",
    "with open(f'{MDLS_PATH}/train.txt', 'w') as file:\n",
    "    tr_ids = list(train_df[train_df['fold'] != split].img.unique())\n",
    "    print('train:', len(tr_ids))\n",
    "    file.write('\\n'.join(tr_ids))\n",
    "with open(f'{MDLS_PATH}/val.txt', 'w') as file:\n",
    "    val_ids = list(train_df[train_df['fold'] == split].img.unique())\n",
    "    print('val:', len(val_ids))\n",
    "    file.write('\\n'.join(val_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@DATASETS.register_module()\n",
    "class SIIMDataset(CustomDataset):\n",
    "    #CLASSES = classes.copy()\n",
    "    CLASSES = ('opacity', )\n",
    "    ANN_DF = train_df.copy()\n",
    "    def load_annotations(self, ann_file):\n",
    "        cat2label = {k: i for i, k in enumerate(self.CLASSES)}\n",
    "        image_list = mmcv.list_from_file(self.ann_file)\n",
    "        data_infos = []\n",
    "        for img_id in image_list:\n",
    "            img_anns = self.ANN_DF[self.ANN_DF.img == img_id]\n",
    "            filename = f'{self.img_prefix}/{img_anns[\"img\"].values[0]}'\n",
    "            data_info = dict(\n",
    "                filename=filename, \n",
    "                width=PARAMS['img_size'], \n",
    "                height=PARAMS['img_size']\n",
    "            )\n",
    "            ratio_x = PARAMS['img_size'] / img_anns['dim_x'].values[0]\n",
    "            ratio_y = PARAMS['img_size'] / img_anns['dim_y'].values[0]\n",
    "            boxes = img_anns['boxes'].values[0]\n",
    "            boxes = json.loads(boxes.replace('\\'', '\\\"'))\n",
    "            gt_bboxes = [\n",
    "                [int(box['x'] * ratio_x), \n",
    "                 int(box['y'] * ratio_y), \n",
    "                 int((box['x'] + box['width']) * ratio_x), \n",
    "                 int((box['y'] + box['height']) * ratio_y)]\n",
    "                for box in boxes]\n",
    "            img_labels = img_anns[classes].values[0]\n",
    "            #gt_labels = [cat2label[label2classes[str(img_labels.tolist())]]] * len(boxes)\n",
    "            gt_labels = [0] * len(boxes)\n",
    "            data_anno = dict(\n",
    "                bboxes=np.array(gt_bboxes, dtype=np.float32).reshape(-1, 4),\n",
    "                labels=np.array(gt_labels),\n",
    "            )\n",
    "            data_info.update(ann=data_anno)\n",
    "            #print(data_anno)\n",
    "            data_infos.append(data_info)\n",
    "        return data_infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = A.Compose([\n",
    "    A.OneOf([\n",
    "        A.RandomBrightness(limit=.2, p=1), \n",
    "        A.RandomContrast(limit=.2, p=1), \n",
    "        A.RandomGamma(p=1)\n",
    "    ], p=.5),\n",
    "    A.OneOf([\n",
    "        A.Blur(blur_limit=3, p=1),\n",
    "        A.MedianBlur(blur_limit=3, p=1)\n",
    "    ], p=.25),\n",
    "    A.OneOf([\n",
    "        A.GaussNoise(0.002, p=.5),\n",
    "        A.IAAAffine(p=.5),\n",
    "    ], p=.25),\n",
    "    A.VerticalFlip(p=.5),\n",
    "    A.HorizontalFlip(p=.5),\n",
    "    A.Transpose(p=.25),\n",
    "    A.RandomRotate90(p=.25),\n",
    "    A.Cutout(num_holes=10, max_h_size=20, max_w_size=20, p=.25),\n",
    "    A.ShiftScaleRotate(p=.5)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = Config.fromfile(f'{WRK_DIR}/configs/{PARAMS[\"config\"]}')\n",
    "cfg.load_from = f'{WRK_DIR}/checkpoints/{PARAMS[\"checkpoint\"]}'\n",
    "#cfg.model.roi_head.bbox_head.num_classes = len(classes)\n",
    "#cfg.model.bbox_head.num_classes = len(classes) # VFNet option\n",
    "cfg.model.bbox_head.num_classes = 1\n",
    "#cfg.model.rpn_head.loss_bbox=dict(\n",
    "#    type='IoULoss', \n",
    "#    loss_weight=1.0)\n",
    "cfg.dump(f'{MDLS_PATH}/init_config.py')\n",
    "\n",
    "cfg.train_pipeline = [\n",
    "    dict(type='LoadImageFromFile'),\n",
    "    dict(type='LoadAnnotations', with_bbox=True),\n",
    "    dict(\n",
    "        type='Resize',\n",
    "        img_scale=[(1333, 640), (1333, 672), (1333, 704), (1333, 736),\n",
    "                   (1333, 768), (1333, 800)],\n",
    "        multiscale_mode='value',\n",
    "        keep_ratio=True),\n",
    "    #dict(type='RandomFlip', flip_ratio=0.25),\n",
    "    ########################################\n",
    "    # Note that this key is part of bbox_params. \n",
    "    # Their difference is format='pascal_voc' means [x1, y1, x2, y2] style box encoding, \n",
    "    # while format='coco' means [x, y, w, h].\n",
    "    dict(\n",
    "        type='Albu',\n",
    "        transforms=train_transforms,\n",
    "        bbox_params=dict(\n",
    "            type='BboxParams',\n",
    "            format='pascal_voc',\n",
    "            label_fields=['gt_labels'],\n",
    "            min_visibility=0.0,\n",
    "            filter_lost_elements=True),\n",
    "        keymap={\n",
    "            'img': 'image',\n",
    "            #'gt_masks': 'masks',\n",
    "            'gt_bboxes': 'bboxes'},\n",
    "        update_pad_shape=False,\n",
    "        skip_img_without_anno=True),\n",
    "    #########################################\n",
    "    dict(\n",
    "        type='Normalize',\n",
    "        mean=[103.53, 116.28, 123.675],\n",
    "        std=[1.0, 1.0, 1.0],\n",
    "        to_rgb=False),\n",
    "    dict(type='Pad', size_divisor=32),\n",
    "    dict(type='DefaultFormatBundle'),\n",
    "    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n",
    "]\n",
    "\n",
    "cfg.dataset_type = 'SIIMDataset'\n",
    "cfg.data_root = IMGS_PATH\n",
    "cfg.data.test.type = 'SIIMDataset'\n",
    "cfg.data.test.data_root = IMGS_PATH\n",
    "cfg.data.test.ann_file = f'{MDLS_PATH}/train.txt'\n",
    "cfg.data.test.img_prefix = ''\n",
    "cfg.data.train.type = 'SIIMDataset'\n",
    "cfg.data.train.data_root = IMGS_PATH\n",
    "cfg.data.train.ann_file = f'{MDLS_PATH}/train.txt'\n",
    "cfg.data.train.img_prefix = ''\n",
    "cfg.data.val.type = 'SIIMDataset'\n",
    "cfg.data.val.data_root = IMGS_PATH\n",
    "cfg.data.val.ann_file = f'{MDLS_PATH}/val.txt'\n",
    "cfg.data.val.img_prefix = ''\n",
    "cfg.work_dir = MDLS_PATH\n",
    "\n",
    "cfg.optimizer.lr = .02 / (8 * 16 / PARAMS['batch_size'])\n",
    "#cfg.optimizer = dict(type='Adam', lr=.001)\n",
    "#cfg.optimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))\n",
    "#cfg.lr_config = dict(\n",
    "#    policy='CosineAnnealing',\n",
    "#    warmup='exp',\n",
    "#    warmup_iters=500,\n",
    "#    warmup_ratio=.1,\n",
    "#    min_lr_ratio=1e-5\n",
    "#)\n",
    "\n",
    "cfg.log_config.interval = 128\n",
    "cfg.runner.max_epochs = PARAMS['epochs']\n",
    "cfg.checkpoint_config.interval = 1\n",
    "cfg.evaluation = dict(\n",
    "    interval=1, \n",
    "    start=2,\n",
    "    metric='mAP', \n",
    "    save_best='mAP')\n",
    "\n",
    "cfg.seed = PARAMS['seed']\n",
    "set_random_seed(0, deterministic=False)\n",
    "\n",
    "cfg.gpu_ids = range(1)\n",
    "cfg.data.samples_per_gpu = PARAMS['batch_size']\n",
    "cfg.data.workers_per_gpu = 2 * PARAMS['batch_size']\n",
    "#cfg.workflow = [('train', 1), ('val', 1)]\n",
    "cfg.workflow = [('train', 1)]\n",
    "\n",
    "cfg.dump(f'{MDLS_PATH}/train_config.py')\n",
    "print(f'Config:\\n{cfg.pretty_text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [build_dataset(cfg.data.train)]\n",
    "if len(cfg.workflow) == 2:\n",
    "    datasets.append(build_dataset(cfg.data.val))\n",
    "model = build_detector(\n",
    "    cfg.model, \n",
    "    train_cfg=cfg.get('train_cfg'), \n",
    "    test_cfg=cfg.get('test_cfg')\n",
    ")\n",
    "model.CLASSES = datasets[0].CLASSES\n",
    "mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))\n",
    "train_detector(model, datasets, cfg, distributed=False, validate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = f'{MDLS_PATH}/epoch_6.pth'\n",
    "cfg = f'{MDLS_PATH}/init_config.py'\n",
    "model_test = init_detector(cfg, checkpoint, device='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TH = .45\n",
    "imgs = []\n",
    "split = PARAMS['val_fold']\n",
    "sample = train_df[train_df['fold'] != split].sample(n=4)['img'].values\n",
    "for img_name in sample:\n",
    "    ratio_x = PARAMS['img_size'] / train_df.loc[train_df['img'] == img_name, 'dim_x'].values[0]\n",
    "    ratio_y = PARAMS['img_size'] / train_df.loc[train_df['img'] == img_name, 'dim_y'].values[0]\n",
    "    boxes = train_df.loc[train_df['img'] == img_name, 'boxes'].values[0]\n",
    "    boxes = json.loads(boxes.replace('\\'', '\\\"'))\n",
    "    boxes = [[int(box['x'] * ratio_x), \n",
    "              int(box['y'] * ratio_y), \n",
    "              int((box['x'] + box['width']) * ratio_x), \n",
    "              int((box['y'] + box['height']) * ratio_y)]\n",
    "             for box in boxes]\n",
    "    img_labels = train_df.loc[train_df['img'] == img_name, classes].values[0]\n",
    "    img_labels = [str(img_labels.tolist())] * len(boxes)\n",
    "    img = cv2.imread(f'{IMGS_PATH}/{img_name}')\n",
    "    for label_id, box in zip(img_labels, boxes):\n",
    "        color = label2color[label_id]\n",
    "        img = draw_bbox(\n",
    "            img, \n",
    "            list(np.int_(box)), \n",
    "            label2classes[label_id], \n",
    "            label2color[label_id]\n",
    "        )\n",
    "    result = inference_detector(model_test, img)\n",
    "    boxes_list = [list(x[:, :4] / PARAMS['img_size']) for x in result if x.shape[0] != 0]\n",
    "    boxes_list =  [item for sublist in boxes_list for item in sublist]\n",
    "    scores_list = [x[:, 4].tolist() for x in result if x.shape[0] != 0]\n",
    "    scores_list =  [item for sublist in scores_list for item in sublist]\n",
    "    labels_list = [[i] * x.shape[0] for i, x in enumerate(result) if x.shape[0] != 0]\n",
    "    labels_list =  [item for sublist in labels_list for item in sublist]\n",
    "    boxes, scores, box_labels = nms(\n",
    "        boxes=[boxes_list], \n",
    "        scores=[scores_list], \n",
    "        labels=[labels_list], \n",
    "        weights=None,\n",
    "        iou_thr=PARAMS['iou_th']\n",
    "    )\n",
    "    boxes *= PARAMS['img_size']\n",
    "    for label_id, box, score in zip(box_labels, boxes, scores):\n",
    "        if score >= TH:\n",
    "            color = [255, 255, 255]\n",
    "            img = draw_bbox(\n",
    "                img, \n",
    "                list(np.int_(box)), \n",
    "                'predict', \n",
    "                color\n",
    "            )\n",
    "    imgs.append(img)\n",
    "plot_imgs(imgs, size=8, cols=4, cmap=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Orange Python 3",
   "language": "python",
   "name": "orange"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
