{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import json\n",
    "import cv2\n",
    "import time\n",
    "import shutil\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pydicom\n",
    "import glob\n",
    "from pydicom.pixel_data_handlers.util import apply_voi_lut\n",
    "import matplotlib.pyplot as plt\n",
    "import albumentations as A\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tqdm import tqdm\n",
    "import sys \n",
    "import timm\n",
    "from timm.models.efficientnet import *\n",
    "import scipy \n",
    "from scipy import stats\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from ast import literal_eval\n",
    "import sklearn \n",
    "from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold \n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, average_precision_score, precision_score \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim \n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import GradScaler, autocast \n",
    "from torch.autograd import Variable\n",
    "from torch.nn.modules.loss import _WeightedLoss\n",
    "import typing as tp\n",
    "try:\n",
    "    from itertools import  ifilterfalse\n",
    "except ImportError: # py3k\n",
    "    from itertools import  filterfalse\n",
    "import warnings \n",
    "if not DEBUG:\n",
    "    warnings.filterwarnings('ignore')\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device('cuda')\n",
    "    print('GPU is available')\n",
    "else:\n",
    "    DEVICE = torch.device('cpu')\n",
    "    print('CPU is used')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KAGGLE = False\n",
    "MDLS_FOLDS = {'vpt3': [0, 1, 2, 3, 4]}\n",
    "MDLS_FOLDS_TWOCLS = {'vptbin0': [0, 1, 2, 3, 4]}\n",
    "if KAGGLE:\n",
    "    DATA_PATH = '../input/siim-covid19-detection'\n",
    "    MDLS_PATHS = {ver: f'../input/siim-tfmodels-{ver}' \n",
    "                  for ver, _ in MDLS_FOLDS.items()}\n",
    "    MDLS_PATHS_TWOCLS = {ver: f'../input/siim-tfmodels-{ver}' \n",
    "                         for ver, _ in MDLS_FOLDS_TWOCLS.items()}\n",
    "else:\n",
    "    DATA_PATH = './data'\n",
    "    MDLS_PATHS = {ver: f'./models_{ver}' \n",
    "                  for ver, _ in MDLS_FOLDS.items()}\n",
    "    MDLS_PATHS_TWOCLS = {ver: f'./models_{ver}' \n",
    "                         for ver, _ in MDLS_FOLDS_TWOCLS.items()}\n",
    "CACHE_PATH = './cache'\n",
    "BATCH_SUBM = 64\n",
    "WORKERS = 8\n",
    "IMG_SIZE = 512\n",
    "TTAS = [0, 1, 2, 3, 4, 5]\n",
    "\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cache images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_xray(path, voi_lut=True, fix_monochrome=True):\n",
    "    dicom = pydicom.read_file(path)\n",
    "    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to \n",
    "    # \"human-friendly\" view\n",
    "    if voi_lut:\n",
    "        data = apply_voi_lut(dicom.pixel_array, dicom)\n",
    "    else:\n",
    "        data = dicom.pixel_array        \n",
    "    # depending on this value, X-ray may look inverted - fix that:\n",
    "    if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n",
    "        data = np.amax(data) - data\n",
    "    data = data - np.min(data)\n",
    "    data = data / np.max(data)\n",
    "    data = (data * 255).astype(np.uint8) \n",
    "    return data\n",
    "\n",
    "def resize(array, size, keep_ratio=False, resample=Image.LANCZOS):\n",
    "    img = Image.fromarray(array)\n",
    "    if keep_ratio:\n",
    "        img.thumbnail((size, size), resample)\n",
    "    else:\n",
    "        img = img.resize((size, size), resample)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepaths = glob.glob(f'{DATA_PATH}/test/**/*dcm', recursive=True)\n",
    "test_df = pd.DataFrame({'path': filepaths, })\n",
    "test_df['image_id'] = test_df.path.map(\n",
    "    lambda x: x.split('/')[-1].replace('.dcm', '') \n",
    "    + '_image'\n",
    ")\n",
    "test_df['study_id'] = test_df.path.map(\n",
    "    lambda x: x.split('/')[-3].replace('.dcm', '') \n",
    "    + '_study'\n",
    ")\n",
    "display(test_df.head())\n",
    "print('test df loaded', test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "counter = 0\n",
    "images_paths = []\n",
    "dim_x = []\n",
    "dim_y = []\n",
    "os.makedirs(CACHE_PATH, exist_ok=True)\n",
    "for file in tqdm(test_df.path, desc='cache progress'):\n",
    "    if file == '':\n",
    "        counter += 1\n",
    "    else:\n",
    "        xray = read_xray(file)\n",
    "        im = resize(xray, size=IMG_SIZE) # keep_ratio=True to have original aspect ratio\n",
    "        im.save(CACHE_PATH + '/' + file.split('/')[-1].replace('dcm', 'png'))\n",
    "        images_paths.append(file.split('/')[-1].replace('dcm', 'png'))\n",
    "        dim_x.append(xray.shape[1])\n",
    "        dim_y.append(xray.shape[0])\n",
    "print('files omitted:', counter)\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print(f'time elapsed: {elapsed_time // 60:.0f} min {elapsed_time % 60:.0f} sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['img'] = images_paths\n",
    "test_df['dim_x'] = dim_x\n",
    "test_df['dim_y'] = dim_y\n",
    "test_df['mc_target'] = 0\n",
    "test_df['None Opacity'] = 0\n",
    "display(test_df.head())\n",
    "print('test df done', test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 classes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_aug = A.Compose([ToTensorV2(p=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flip(img, axis=0):\n",
    "    if axis == 1:\n",
    "        return img[::-1, :, :]\n",
    "    elif axis == 2:\n",
    "        return img[:, ::-1, :]\n",
    "    elif axis == 3:\n",
    "        return img[::-1, ::-1, :]\n",
    "    elif axis == 4:\n",
    "        return np.rot90(img, axes=(1, 0))\n",
    "    elif axis == 5:\n",
    "        return np.rot90(img, axes=(0, 1))\n",
    "    else:\n",
    "        return img\n",
    "    \n",
    "class StudyDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, df, target='mc_target', \n",
    "                 tab_data=None, aug=None, tta=None):\n",
    "        super().__init__()\n",
    "        self.df = df \n",
    "        self.aug = aug \n",
    "        self.target = target\n",
    "        self.tab_data = tab_data\n",
    "        self.tta = tta\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = cv2.imread(f'{CACHE_PATH}/{self.df[\"img\"][idx]}')\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  \n",
    "        mask = np.zeros((image.shape[0], image.shape[1]))\n",
    "        if self.tta: \n",
    "            image = flip(image.copy(), axis=self.tta)\n",
    "        if self.aug:\n",
    "            augmented = self.aug(image=image.copy(), mask=mask)\n",
    "            image = augmented['image'] / 255\n",
    "            mask = augmented['mask'] / 255\n",
    "        else:\n",
    "            image = torch.from_numpy(image).float()\n",
    "            image = image.permute(2, 1, 0) / 255\n",
    "            mask = mask / 255\n",
    "        target = self.df[self.target][idx]\n",
    "        if self.tab_data:\n",
    "            tab_data = self.df[['modality','sex','body_part']].values\n",
    "            tab_data = tab_data[idx]\n",
    "            tab_data = torch.tensor(tab_data)\n",
    "            return image, target, mask, tab_data \n",
    "        else:\n",
    "            return image, target, mask\n",
    "    \n",
    "dataset_show = StudyDataset(\n",
    "    df=test_df,\n",
    "    aug=valid_aug,\n",
    "    tta=4\n",
    ")\n",
    "img_show, lbl_show, mask_show = dataset_show.__getitem__(2)\n",
    "img_show = img_show.numpy().transpose([1, 2, 0])\n",
    "img_show = np.clip(img_show, 0, 1)\n",
    "plt.imshow(img_show)\n",
    "plt.title('image, target ' + str(lbl_show))\n",
    "plt.show()\n",
    "plt.imshow(mask_show)\n",
    "plt.title('mask, target ' + str(lbl_show))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self, params, n_classes=4, tab_flag=False):\n",
    "        super(Net, self).__init__()\n",
    "        e = timm.create_model(params['model_arch'], pretrained=False)\n",
    "        self.b0 = nn.Sequential(\n",
    "            e.conv_stem,\n",
    "            e.bn1,\n",
    "            e.act1\n",
    "        )\n",
    "        self.b1 = e.blocks[0]\n",
    "        self.b2 = e.blocks[1]\n",
    "        self.b3 = e.blocks[2]\n",
    "        self.b4 = e.blocks[3]\n",
    "        self.b5 = e.blocks[4]\n",
    "        self.b6 = e.blocks[5]\n",
    "        self.b7 = e.blocks[6]\n",
    "        self.b8 = nn.Sequential(\n",
    "            e.conv_head, \n",
    "            e.bn2,\n",
    "            e.act2\n",
    "        )\n",
    "        self.final_eff_layer = nn.Linear(e.classifier.in_features, 1000)\n",
    "        self.mask = nn.Sequential(\n",
    "            nn.Conv2d(176, 160, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(160),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(160, 160, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(160),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(160, 1, kernel_size=1, padding=0),\n",
    "        )\n",
    "        self.tab_flag = tab_flag\n",
    "        if self.tab_flag:\n",
    "            # Tab layers \n",
    "            num_features = 3\n",
    "            self.hidden_size = [10, 6] \n",
    "            self.batch_norm1 = nn.BatchNorm1d(num_features)\n",
    "            self.linear1 = nn.Linear(num_features, self.hidden_size[0])\n",
    "            self.batch_norm2 = nn.BatchNorm1d(self.hidden_size[0])\n",
    "            self.linear2 = nn.Linear(self.hidden_size[0], self.hidden_size[1])\n",
    "            # FINAL LAYER \n",
    "            self.final = nn.Linear(1006, n_classes)\n",
    "        else:\n",
    "            self.final = nn.Linear(1000, n_classes)\n",
    "\n",
    "    # @torch.cuda.amp.autocast()\n",
    "    def forward(self, image, tab_data=None):\n",
    "        # Image layers\n",
    "        batch_size = len(image)\n",
    "        x = 2 * image - 1    \n",
    "        x = self.b0(x) \n",
    "        x = self.b1(x) \n",
    "        x = self.b2(x) \n",
    "        x = self.b3(x) \n",
    "        x = self.b4(x)\n",
    "        x = self.b5(x) \n",
    "        # ============ #\n",
    "        mask = self.mask(x)\n",
    "        # ============ #\n",
    "        x = self.b6(x) \n",
    "        x = self.b7(x) \n",
    "        x = self.b8(x)\n",
    "        x = F.adaptive_avg_pool2d(x, 1).reshape(batch_size, -1)\n",
    "        x = self.final_eff_layer(x)\n",
    "        if tab_data:\n",
    "            # TAB layers \n",
    "            y = self.batch_norm1(tab_data)\n",
    "            y = F.relu(self.linear1(y))\n",
    "            y = self.batch_norm2(y)\n",
    "            y = F.relu(self.linear2(y))\n",
    "            # Final Layers \n",
    "            x = torch.cat((x, y), dim=1)  # Concatenating image feats + tab feats \n",
    "        x = F.relu(x)\n",
    "        logit = self.final(x)\n",
    "        return logit, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets, loaders = [], []\n",
    "for tta in TTAS:\n",
    "    dataset = StudyDataset(\n",
    "        df=test_df,\n",
    "        aug=valid_aug,\n",
    "        tta=tta\n",
    "    )\n",
    "    loader = torch.utils.data.DataLoader(\n",
    "        dataset, \n",
    "        batch_size=BATCH_SUBM,\n",
    "        shuffle=False,\n",
    "        num_workers=WORKERS\n",
    "    )\n",
    "    datasets.append(dataset)\n",
    "    loaders.append(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "for ver, folds in MDLS_FOLDS.items():\n",
    "    with open(f'{MDLS_PATHS[ver]}/params.json') as file:\n",
    "        params = json.load(file)\n",
    "    print('version:', ver, '| loaded params:', params, '\\n')\n",
    "    for fold in folds:\n",
    "        model = Net(params) \n",
    "        path = f'{MDLS_PATHS[ver]}/model_best_fold_{fold}.pth'\n",
    "        state_dict = torch.load(path, map_location=torch.device('cpu'))\n",
    "        model.load_state_dict(state_dict)\n",
    "        model.float()\n",
    "        model.eval()\n",
    "        model.cuda(DEVICE)\n",
    "        models.append(model)\n",
    "        print('loaded:', path)\n",
    "    del state_dict, model; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "with torch.no_grad():\n",
    "    for i, model in enumerate(models):\n",
    "        for j, loader in enumerate(loaders):\n",
    "            preds_tta = []\n",
    "            for data in tqdm(loader, desc=f'model {i}, loader {j}'):\n",
    "                img_data = data[0]\n",
    "                img_data = img_data.to(DEVICE)\n",
    "                logits, _ = model(img_data)\n",
    "                probs = torch.softmax(logits, 1)\n",
    "                probs = np.squeeze(probs.cpu().numpy())\n",
    "                preds_tta.extend(probs.tolist())\n",
    "            preds.append(preds_tta)\n",
    "preds = np.mean(preds, axis=0)\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print(f'time elapsed: {elapsed_time // 60:.0f} min {elapsed_time % 60:.0f} sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "name2fname = {\n",
    "    'Negative for Pneumonia': 'negative', \n",
    "    'Typical Appearance': 'typical', \n",
    "    'Indeterminate Appearance': 'indeterminate', \n",
    "    'Atypical Appearance': 'atypical'\n",
    "    \n",
    "}\n",
    "name2label = {v: i for i, (k, v) in enumerate(name2fname.items())}\n",
    "print(name2label)\n",
    "label2name  = {v:k for k, v in name2label.items()}\n",
    "print(label2name)\n",
    "cols_classes = [str(x) for x in list(name2label.values())]\n",
    "for i, col in enumerate(cols_classes):\n",
    "    test_df[col] = preds[:, i]\n",
    "display(test_df.head())\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 classes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "for ver, folds in MDLS_FOLDS_TWOCLS.items():\n",
    "    with open(f'{MDLS_PATHS_TWOCLS[ver]}/params.json') as file:\n",
    "        params = json.load(file)\n",
    "    print('version:', ver, '| loaded params:', params, '\\n')\n",
    "    for fold in folds:\n",
    "        model = Net(params, n_classes=1) \n",
    "        path = f'{MDLS_PATHS_TWOCLS[ver]}/model_best_fold_{fold}.pth'\n",
    "        state_dict = torch.load(path, map_location=torch.device('cpu'))\n",
    "        model.load_state_dict(state_dict)\n",
    "        model.float()\n",
    "        model.eval()\n",
    "        model.cuda(DEVICE)\n",
    "        models.append(model)\n",
    "        print('loaded:', path)\n",
    "    del state_dict, model; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "with torch.no_grad():\n",
    "    for i, model in enumerate(models):\n",
    "        for j, loader in enumerate(loaders):\n",
    "            preds_tta = []\n",
    "            for data in tqdm(loader, desc=f'model {i}, loader {j}'):\n",
    "                img_data = data[0]\n",
    "                img_data = img_data.to(DEVICE)\n",
    "                logits, _ = model(img_data)\n",
    "                probs = torch.sigmoid(logits)\n",
    "                probs = np.squeeze(probs.cpu().numpy())\n",
    "                preds_tta.extend(probs.tolist())\n",
    "            preds.append(preds_tta)\n",
    "preds = np.mean(preds, axis=0)\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print(f'time elapsed: {elapsed_time // 60:.0f} min {elapsed_time % 60:.0f} sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.loc[:, 'None Opacity'] = preds\n",
    "display(test_df.head())\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MMDet model infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mmcv\n",
    "import mmdet\n",
    "from ensemble_boxes import *\n",
    "from mmdet.apis import init_detector, inference_detector\n",
    "print(mmdet.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BXS = True\n",
    "VER_BXS = 'v0'\n",
    "if KAGGLE:\n",
    "    MDLS_BXS_PATH = f'../input/siim-mmdetection-train-demo' \n",
    "else:\n",
    "    MDLS_BXS_PATH = f'/u01/mrorange/siim/models_mmdet_{VER_BXS}'\n",
    "TH = .35\n",
    "IOU_TH = .6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{MDLS_BXS_PATH}/params.json') as file:\n",
    "    params_bxs = json.load(file)\n",
    "print(params_bxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = f'{MDLS_BXS_PATH}/epoch_6.pth'\n",
    "cfg = f'{MDLS_BXS_PATH}/init_config.py'\n",
    "model_bxs = init_detector(cfg, checkpoint, device='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_imgs(imgs, cols=2, size=10, is_rgb=True, title='', cmap='gray', img_size=None):\n",
    "    rows = len(imgs) // cols + 1\n",
    "    fig = plt.figure(figsize=(cols * size, rows * size))\n",
    "    for i, img in enumerate(imgs):\n",
    "        if img_size is not None:\n",
    "            img = cv2.resize(img, img_size)\n",
    "        fig.add_subplot(rows, cols, i + 1)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(img, cmap=cmap)\n",
    "    plt.suptitle(title)\n",
    "    plt.axis('off')\n",
    "    \n",
    "def draw_bbox(img, box, label, color, thickness=3):   \n",
    "    alpha = .1\n",
    "    alpha_box = .4\n",
    "    overlay_bbox = img.copy()\n",
    "    overlay_text = img.copy()\n",
    "    output = img.copy()\n",
    "    text_width, text_height = cv2.getTextSize(label.upper(), cv2.FONT_HERSHEY_SIMPLEX, .6, 1)[0]\n",
    "    cv2.rectangle(overlay_bbox, \n",
    "                  (box[0], box[1]), \n",
    "                  (box[2], box[3]), \n",
    "                  color, -1)\n",
    "    cv2.addWeighted(overlay_bbox, alpha, output, 1 - alpha, 0, output)\n",
    "    cv2.rectangle(overlay_text, \n",
    "                  (box[0], box[1] - 7 - text_height), \n",
    "                  (box[0] + text_width + 2, box[1]),\n",
    "                  (0, 0, 0), -1)\n",
    "    cv2.addWeighted(overlay_text, alpha_box, output, 1 - alpha_box, 0, output)\n",
    "    cv2.rectangle(output, \n",
    "                  (box[0], box[1]), \n",
    "                  (box[2], box[3]),\n",
    "                  color, thickness)\n",
    "    cv2.putText(output, \n",
    "                label.upper(), \n",
    "                (box[0], box[1]-5),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                .6, (255, 255, 255), 1, \n",
    "                cv2.LINE_AA)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_idxs = test_df.img.values\n",
    "imgs = []\n",
    "preds_bxs = []\n",
    "for i, img_name in enumerate(tqdm(imgs_idxs, desc=f'test {ver}')):\n",
    "    ratio_x = IMG_SIZE / test_df.loc[test_df['img'] == img_name, 'dim_x'].values[0]\n",
    "    ratio_y = IMG_SIZE / test_df.loc[test_df['img'] == img_name, 'dim_y'].values[0]\n",
    "    img = cv2.imread(f'{CACHE_PATH}/{img_name}')\n",
    "    result = inference_detector(model_bxs, img)\n",
    "    boxes_list = [list(x[:, :4] / IMG_SIZE) for x in result if x.shape[0] != 0]\n",
    "    boxes_list =  [item for sublist in boxes_list for item in sublist]\n",
    "    scores_list = [x[:, 4].tolist() for x in result if x.shape[0] != 0]\n",
    "    scores_list =  [item for sublist in scores_list for item in sublist]\n",
    "    labels_list = [[i] * x.shape[0] for i, x in enumerate(result) if x.shape[0] != 0]\n",
    "    labels_list =  [item for sublist in labels_list for item in sublist]\n",
    "    boxes, scores, box_labels = nms(\n",
    "        boxes=[boxes_list], \n",
    "        scores=[scores_list], \n",
    "        labels=[labels_list], \n",
    "        weights=None,\n",
    "        iou_thr=IOU_TH\n",
    "    )\n",
    "    boxes *= IMG_SIZE\n",
    "    if i <= 3:\n",
    "        for label_id, box, score in zip(box_labels, boxes, scores):\n",
    "            if score >= TH:\n",
    "                color = [255, 255, 255]\n",
    "                img = draw_bbox(\n",
    "                    img, \n",
    "                    list(np.int_(box)), \n",
    "                    'predict', \n",
    "                    color\n",
    "                )\n",
    "        imgs.append(img)\n",
    "    string = ''\n",
    "    for label_id, box, score in zip(box_labels, boxes, scores):\n",
    "        if score >= TH:\n",
    "            str_boxes = ' '.join([\n",
    "                str(int(box[0] / ratio_x)),\n",
    "                str(int(box[1] / ratio_y)),\n",
    "                str(int(box[2] / ratio_x)),\n",
    "                str(int(box[3] / ratio_y))\n",
    "            ])\n",
    "            string += f'opacity {score:0.2f} {str_boxes} '\n",
    "    string = string.strip()\n",
    "    preds_bxs.append(string if string else 'none 1 0 0 1 1')\n",
    "plot_imgs(imgs, size=8, cols=4, cmap=None)\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print(f'time elapsed: {elapsed_time // 60:.0f} min {elapsed_time % 60:.0f} sec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post-processing for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if BXS:\n",
    "    image_df = pd.DataFrame({\n",
    "        'image_id': test_df.image_id.tolist(),\n",
    "        'PredictionString_img': preds_bxs\n",
    "    })\n",
    "else:\n",
    "    image_df = pd.DataFrame({\n",
    "        'image_id': test_df.image_id.tolist(),\n",
    "        'PredictionString_img': [\"none 1 0 0 1 1\"] * len(test_df.image_id.tolist())\n",
    "    })\n",
    "display(image_df.head())\n",
    "print('image df done', image_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_df[image_df['image_id'] == '1b282faf0f42_image']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predstring(row, thr=0):\n",
    "    string = ''\n",
    "    for idx in range(4):\n",
    "        conf =  row[str(idx)]\n",
    "        if conf > thr:\n",
    "            string += f'{label2name[idx]} {conf:0.2f} 0 0 1 1 '\n",
    "    string = string.strip()\n",
    "    return string\n",
    "\n",
    "def get_prednoneop(row):\n",
    "    string = row['PredictionString_img']\n",
    "    if string != 'none 1 0 0 1 1':\n",
    "        string += f' none {row[\"None Opacity\"]:0.2f} 0 0 1 1'\n",
    "    string = string.strip()\n",
    "    return string\n",
    "\n",
    "cols = ['image_id', 'study_id']\n",
    "print('test shape:', test_df.shape)\n",
    "subm_df = pd.merge(test_df[cols], image_df, \n",
    "                   left_on='image_id', right_on='image_id', \n",
    "                   how='left')\n",
    "subm_df = pd.merge(subm_df, \n",
    "                   test_df.groupby(['study_id'])[cols_classes].mean().reset_index(), \n",
    "                   left_on='study_id', right_on='study_id', \n",
    "                   how='left')\n",
    "subm_df = pd.merge(subm_df, \n",
    "                   test_df.groupby(['study_id'])['None Opacity'].mean().reset_index(), \n",
    "                   left_on='study_id', right_on='study_id', \n",
    "                   how='left')\n",
    "subm_df['PredictionString_sty'] = subm_df.apply(get_predstring, axis=1)\n",
    "subm_df['PredictionString_img'] = subm_df.apply(get_prednoneop, axis=1)\n",
    "display(subm_df.head())\n",
    "print('unique study ids:', len(subm_df.study_id.unique()))\n",
    "print('unique image ids:', len(subm_df.image_id.unique()))\n",
    "print('subm shape:', subm_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cols = {'image_id': 'img', 'study_id': 'id'}\n",
    "classes = [str(x) for x in list(name2fname.keys())]\n",
    "new_cols.update({k: v for k, v in zip(cols_classes, classes)})\n",
    "pseudo_df = subm_df[\n",
    "    ['image_id', 'study_id'] + cols_classes + ['None Opacity']\n",
    "].rename(columns=new_cols).drop_duplicates()\n",
    "pseudo_df.to_csv('pseudo_study_level.csv', index=False)\n",
    "display(pseudo_df.head())\n",
    "print('submission done:', pseudo_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subm_df = pd.concat([\n",
    "    subm_df[['image_id', 'PredictionString_img']].rename(\n",
    "        columns={'image_id': 'id', 'PredictionString_img': 'PredictionString'}\n",
    "    ).drop_duplicates(), \n",
    "    subm_df[['study_id', 'PredictionString_sty']].rename(\n",
    "        columns={'study_id': 'id', 'PredictionString_sty': 'PredictionString'}\n",
    "    ).drop_duplicates()\n",
    "])\n",
    "subm_df.to_csv('submission.csv', index=False)\n",
    "display(subm_df.head())\n",
    "print('submission done:', subm_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(CACHE_PATH)\n",
    "print(f'{CACHE_PATH} -> cache deleted')\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print(f'time elapsed: {elapsed_time // 60:.0f} min {elapsed_time % 60:.0f} sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Orange Python 3",
   "language": "python",
   "name": "orange"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
